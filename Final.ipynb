{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d5cec7e7d534175a0c15cd623d59312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a201b986ea7c45b2b94ce1a13d2520de",
              "IPY_MODEL_c616727da4f14332b4b9eb81f5d84b11",
              "IPY_MODEL_a9ce8d6c1aad4d9897c69017b8999737"
            ],
            "layout": "IPY_MODEL_f8eb286a02d74fdd9145cbd1693f688a"
          }
        },
        "a201b986ea7c45b2b94ce1a13d2520de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9081a39aa6c4f2f950daffc6856aae3",
            "placeholder": "​",
            "style": "IPY_MODEL_c6523878d0724703a0a05c7cdc7c8858",
            "value": "modules.json: 100%"
          }
        },
        "c616727da4f14332b4b9eb81f5d84b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a89ee5d4852480da7baf4a118b0e0fa",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bde9696f44b4237b1231245ae7e05bc",
            "value": 229
          }
        },
        "a9ce8d6c1aad4d9897c69017b8999737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e64f84ec9a0c41ad82f7fe1dfd7d80d7",
            "placeholder": "​",
            "style": "IPY_MODEL_22f3d22c36e34f5f813c33f8e072909a",
            "value": " 229/229 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "f8eb286a02d74fdd9145cbd1693f688a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9081a39aa6c4f2f950daffc6856aae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6523878d0724703a0a05c7cdc7c8858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a89ee5d4852480da7baf4a118b0e0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bde9696f44b4237b1231245ae7e05bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e64f84ec9a0c41ad82f7fe1dfd7d80d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f3d22c36e34f5f813c33f8e072909a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5deab07b3d497db0202365a8c29251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6deb564efb974435b78c6caea029727b",
              "IPY_MODEL_ff7804d0a45048bd8e41aecb4e22909c",
              "IPY_MODEL_087aeedfd67e43039bdb2f2865cdb361"
            ],
            "layout": "IPY_MODEL_a458e740123b4c209598902c7aa0b005"
          }
        },
        "6deb564efb974435b78c6caea029727b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e764c15d5e74b1c91e4d8a60f2ac4fe",
            "placeholder": "​",
            "style": "IPY_MODEL_929a815731104380bac684351d13d14a",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "ff7804d0a45048bd8e41aecb4e22909c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99fe196e56e64b128b8373b6c43a91b6",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97d310bcdce54a40af9e68f1233b0033",
            "value": 122
          }
        },
        "087aeedfd67e43039bdb2f2865cdb361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_156bef3068344d46a2aee3b2fce6644b",
            "placeholder": "​",
            "style": "IPY_MODEL_4766519ffafb4c9699843ee8acb66530",
            "value": " 122/122 [00:00&lt;00:00, 8.33kB/s]"
          }
        },
        "a458e740123b4c209598902c7aa0b005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e764c15d5e74b1c91e4d8a60f2ac4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929a815731104380bac684351d13d14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99fe196e56e64b128b8373b6c43a91b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97d310bcdce54a40af9e68f1233b0033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "156bef3068344d46a2aee3b2fce6644b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4766519ffafb4c9699843ee8acb66530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e64adb5d69f4762b3fcdebd642dd8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e230071982d4960ab60c7a0965dd988",
              "IPY_MODEL_6b1515cc16ad476eb6b7e5300ebf8a95",
              "IPY_MODEL_f8dd8224d68b4dcdbee2270346188756"
            ],
            "layout": "IPY_MODEL_e4b81d1241be4c3f9b26f6d7e36c71f0"
          }
        },
        "4e230071982d4960ab60c7a0965dd988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551a58f3370449de80c7559f4a3824bd",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e9a1b8a6b14aa5b271cd7abb45dc1b",
            "value": "README.md: 100%"
          }
        },
        "6b1515cc16ad476eb6b7e5300ebf8a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed81e98ebb2b4586a6bb5b88f84f2a44",
            "max": 4126,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be0f7b2d9799404a878918a661766cc8",
            "value": 4126
          }
        },
        "f8dd8224d68b4dcdbee2270346188756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f07762d084374e03a58b4465b49fa36a",
            "placeholder": "​",
            "style": "IPY_MODEL_c1c4ddf20de04f1eb356707513a50962",
            "value": " 4.13k/4.13k [00:00&lt;00:00, 271kB/s]"
          }
        },
        "e4b81d1241be4c3f9b26f6d7e36c71f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551a58f3370449de80c7559f4a3824bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e9a1b8a6b14aa5b271cd7abb45dc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed81e98ebb2b4586a6bb5b88f84f2a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0f7b2d9799404a878918a661766cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f07762d084374e03a58b4465b49fa36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c4ddf20de04f1eb356707513a50962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cd7c63c12294326856adf379b6e6471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2de5b9afc9464ab486b28948a422989a",
              "IPY_MODEL_db5f2e4cccdf4ed8b3707c4469806654",
              "IPY_MODEL_36f86afce6c045f2b873ae32e59adae8"
            ],
            "layout": "IPY_MODEL_e6cd5ef4ec304b9d861d5918280aecdb"
          }
        },
        "2de5b9afc9464ab486b28948a422989a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d9719a825224b79963ba61fb8fb5d44",
            "placeholder": "​",
            "style": "IPY_MODEL_69bdd9074776494080dca2ebcd203938",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "db5f2e4cccdf4ed8b3707c4469806654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4d0f3a0845044b8828098d9db080327",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e963f1b0e2c644deb3fdfe2ac8e2ffef",
            "value": 53
          }
        },
        "36f86afce6c045f2b873ae32e59adae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0c896a88b7240fda586d08aa80b3bad",
            "placeholder": "​",
            "style": "IPY_MODEL_8a96a1af16fc4aa496031e20f6e31992",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.10kB/s]"
          }
        },
        "e6cd5ef4ec304b9d861d5918280aecdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9719a825224b79963ba61fb8fb5d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69bdd9074776494080dca2ebcd203938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4d0f3a0845044b8828098d9db080327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e963f1b0e2c644deb3fdfe2ac8e2ffef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0c896a88b7240fda586d08aa80b3bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a96a1af16fc4aa496031e20f6e31992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7f5323f66804e93a8f0bf06c283ade4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b12e093025f4424bad813e69b9158f4",
              "IPY_MODEL_53c787c47a7d491c953ef068e6d41617",
              "IPY_MODEL_608c5f57004c4f789e312bc2aad602aa"
            ],
            "layout": "IPY_MODEL_92d2a6a498de4d91aee8d6c476e0f60d"
          }
        },
        "8b12e093025f4424bad813e69b9158f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4119417cc9ed4b4797e8f194bf6311bf",
            "placeholder": "​",
            "style": "IPY_MODEL_ac630682054643c4915f11e541599d93",
            "value": "config.json: 100%"
          }
        },
        "53c787c47a7d491c953ef068e6d41617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2d1f6f9274c421eb8f85a282bf2fd8b",
            "max": 723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cd4b40ae3d14d67b958229f28b53ca4",
            "value": 723
          }
        },
        "608c5f57004c4f789e312bc2aad602aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fde63035fc3d4e8cab5dd2a78bf70679",
            "placeholder": "​",
            "style": "IPY_MODEL_385d41cf513b4055aa06056df91d433a",
            "value": " 723/723 [00:00&lt;00:00, 43.4kB/s]"
          }
        },
        "92d2a6a498de4d91aee8d6c476e0f60d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4119417cc9ed4b4797e8f194bf6311bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac630682054643c4915f11e541599d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2d1f6f9274c421eb8f85a282bf2fd8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd4b40ae3d14d67b958229f28b53ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fde63035fc3d4e8cab5dd2a78bf70679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385d41cf513b4055aa06056df91d433a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac3724e53cce4630875216763c143b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c962bc1e0834828af08a43a21ecae28",
              "IPY_MODEL_0017a49109fe4e6bb1594753b58923d9",
              "IPY_MODEL_ddfd30f852c54b68838d8d04b08bb16d"
            ],
            "layout": "IPY_MODEL_a94e4ac017224ee4b8325aed5321d45a"
          }
        },
        "8c962bc1e0834828af08a43a21ecae28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3de265818e5747aa9179b0762044b37a",
            "placeholder": "​",
            "style": "IPY_MODEL_6475edff589247bb8b6ae1bfe107f658",
            "value": "model.safetensors: 100%"
          }
        },
        "0017a49109fe4e6bb1594753b58923d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_213e1fd9ebce41f490d7acdd3f0d803e",
            "max": 1112201288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36a93e23c2314b39b4c7bf705768fdee",
            "value": 1112201288
          }
        },
        "ddfd30f852c54b68838d8d04b08bb16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffa072257a304fc6bac003afaff66647",
            "placeholder": "​",
            "style": "IPY_MODEL_60c28a3ef3db4817a167f2d26f1b2985",
            "value": " 1.11G/1.11G [00:09&lt;00:00, 155MB/s]"
          }
        },
        "a94e4ac017224ee4b8325aed5321d45a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de265818e5747aa9179b0762044b37a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6475edff589247bb8b6ae1bfe107f658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "213e1fd9ebce41f490d7acdd3f0d803e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a93e23c2314b39b4c7bf705768fdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffa072257a304fc6bac003afaff66647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c28a3ef3db4817a167f2d26f1b2985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1323956e26144970a48bc9e9039d98a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_730fd74a5607435e9abd5bff210a8106",
              "IPY_MODEL_e763404af11142138d3843a088ea57f5",
              "IPY_MODEL_8754f0d524cf47ada05ac24af2f11c74"
            ],
            "layout": "IPY_MODEL_2b2d84f0932e42e8a0b870e5e4446fc5"
          }
        },
        "730fd74a5607435e9abd5bff210a8106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a536079d6e7a4720ad2af88a48119eab",
            "placeholder": "​",
            "style": "IPY_MODEL_0d294214ec784d68982ba1f3e2c4a6fb",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e763404af11142138d3843a088ea57f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872aa787ad2440c6bc9e71f8fe73b2ab",
            "max": 402,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18114fe70f3048e48f9f777a17d765e6",
            "value": 402
          }
        },
        "8754f0d524cf47ada05ac24af2f11c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03600ee58aec4404a6ca94db7ba030a0",
            "placeholder": "​",
            "style": "IPY_MODEL_bf4a8de70de544dda42085830fcde231",
            "value": " 402/402 [00:00&lt;00:00, 25.4kB/s]"
          }
        },
        "2b2d84f0932e42e8a0b870e5e4446fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a536079d6e7a4720ad2af88a48119eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d294214ec784d68982ba1f3e2c4a6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "872aa787ad2440c6bc9e71f8fe73b2ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18114fe70f3048e48f9f777a17d765e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03600ee58aec4404a6ca94db7ba030a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4a8de70de544dda42085830fcde231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c223292075ac45f4abf68e0de5735f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dbc62c0b50945b4b042b74d8ea40edb",
              "IPY_MODEL_0b8550d8ab9c4eb384b192fa55a6e076",
              "IPY_MODEL_5bc104c4252148a5aa700f27054127dc"
            ],
            "layout": "IPY_MODEL_251463becaeb4071b5f3158d5d8f13d8"
          }
        },
        "8dbc62c0b50945b4b042b74d8ea40edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4bcee068691487caf612320e7f913c3",
            "placeholder": "​",
            "style": "IPY_MODEL_6759311903b94ec5aced9ff5ec0e3953",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "0b8550d8ab9c4eb384b192fa55a6e076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df0d9897eaf42478ca0058d547dabfb",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_237a60ac2fa9485ea3319b925c2e2c87",
            "value": 5069051
          }
        },
        "5bc104c4252148a5aa700f27054127dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_602b4c80fea54d51b8622d0f78185c57",
            "placeholder": "​",
            "style": "IPY_MODEL_5ecc2660a24b4627896fb14872e5809f",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 146MB/s]"
          }
        },
        "251463becaeb4071b5f3158d5d8f13d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4bcee068691487caf612320e7f913c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6759311903b94ec5aced9ff5ec0e3953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7df0d9897eaf42478ca0058d547dabfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "237a60ac2fa9485ea3319b925c2e2c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "602b4c80fea54d51b8622d0f78185c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ecc2660a24b4627896fb14872e5809f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2e7414353a949709d343af7e2f10603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c4ab88c94184f51bf62e9d2012b26ca",
              "IPY_MODEL_e5a8853a3f5f4183a1f3083cf8d4fd88",
              "IPY_MODEL_02883d5580ac4da4a1d17c4892275bd6"
            ],
            "layout": "IPY_MODEL_75507e538444493cb9a695e6343a8b88"
          }
        },
        "9c4ab88c94184f51bf62e9d2012b26ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593230fae8ce44909361ecdc94e50ccd",
            "placeholder": "​",
            "style": "IPY_MODEL_8b2cafccf6d54d4bb7b0e8e1753c22a3",
            "value": "tokenizer.json: 100%"
          }
        },
        "e5a8853a3f5f4183a1f3083cf8d4fd88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2692f8540634cc881ae502fedf0551a",
            "max": 9081518,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_859befbbe54c43ebb2600dbb67bf2bca",
            "value": 9081518
          }
        },
        "02883d5580ac4da4a1d17c4892275bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91eda1bf255844f0bcc60cd7902a3b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_0e17942600dd455b9e49af6b7c3fab2d",
            "value": " 9.08M/9.08M [00:01&lt;00:00, 5.20MB/s]"
          }
        },
        "75507e538444493cb9a695e6343a8b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593230fae8ce44909361ecdc94e50ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2cafccf6d54d4bb7b0e8e1753c22a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2692f8540634cc881ae502fedf0551a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "859befbbe54c43ebb2600dbb67bf2bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91eda1bf255844f0bcc60cd7902a3b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e17942600dd455b9e49af6b7c3fab2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30452802d39e4b46897ee93bdf138b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52af2fc074ab44a0967b32664b95dd6a",
              "IPY_MODEL_543d21e7648e4d7db0a60f81dfa33283",
              "IPY_MODEL_8fc0f8f36c4f4220ad655076eaacfcf6"
            ],
            "layout": "IPY_MODEL_25cbacccb3ab4a61a2e60383b4e6872d"
          }
        },
        "52af2fc074ab44a0967b32664b95dd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb613cfd254a42529bc3dd61f4c69daa",
            "placeholder": "​",
            "style": "IPY_MODEL_2c54d25b6a0545c29a35be9759130c3d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "543d21e7648e4d7db0a60f81dfa33283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37d2472730c44f4ea5329714c2ac6e6b",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_170303c47577423fbdcc945edf8b1f8d",
            "value": 239
          }
        },
        "8fc0f8f36c4f4220ad655076eaacfcf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0d47555e4fe48c0b0ecc048f267623a",
            "placeholder": "​",
            "style": "IPY_MODEL_160ba692be0c4e1cb3e26f7470bb041e",
            "value": " 239/239 [00:00&lt;00:00, 17.8kB/s]"
          }
        },
        "25cbacccb3ab4a61a2e60383b4e6872d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb613cfd254a42529bc3dd61f4c69daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c54d25b6a0545c29a35be9759130c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37d2472730c44f4ea5329714c2ac6e6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170303c47577423fbdcc945edf8b1f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0d47555e4fe48c0b0ecc048f267623a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160ba692be0c4e1cb3e26f7470bb041e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "137841e89e5144a49a9472d12f04516f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eae1513489b1490cb08b5b1122945191",
              "IPY_MODEL_8a5179270dbd4ec39d13f0b66fb516af",
              "IPY_MODEL_a0f1884c9fa446d8b5bb263897a5a94d"
            ],
            "layout": "IPY_MODEL_1be378f2746b40b8a187ecd1515eb3bf"
          }
        },
        "eae1513489b1490cb08b5b1122945191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_185238e69f3648c9b10385f6a55a68f8",
            "placeholder": "​",
            "style": "IPY_MODEL_5e8b3e59c98a423b8746bf34fc07ea28",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "8a5179270dbd4ec39d13f0b66fb516af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cea3dbededa4f35b8a3aa981904dc1b",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f5e47ea836f43d29e5b45f8ed0bb482",
            "value": 190
          }
        },
        "a0f1884c9fa446d8b5bb263897a5a94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322ba9efa5c44f88adb7b136d6eaa8a6",
            "placeholder": "​",
            "style": "IPY_MODEL_a98f09813f714e818d27d648cd16bbe7",
            "value": " 190/190 [00:00&lt;00:00, 7.44kB/s]"
          }
        },
        "1be378f2746b40b8a187ecd1515eb3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185238e69f3648c9b10385f6a55a68f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8b3e59c98a423b8746bf34fc07ea28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cea3dbededa4f35b8a3aa981904dc1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5e47ea836f43d29e5b45f8ed0bb482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "322ba9efa5c44f88adb7b136d6eaa8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98f09813f714e818d27d648cd16bbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "63j5PRh5SpUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone nemo\n",
        "!git clone https://github.com/AI4Bharat/NeMo.git -b nemo-v2\n",
        "\n",
        "# conda install -c nvidia cuda-nvprof=12.2 # Cuda version\n",
        "!pip install packaging\n",
        "!pip install huggingface_hub==0.23.2\n",
        "\n",
        "# install NeMo\n",
        "%cd NeMo\n",
        "!bash reinstall.sh"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mmdQIJadTJmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary imports"
      ],
      "metadata": {
        "id": "sEtMaxK0dmnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import soundfile as sf\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import IPython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYQ4sQ5wZUgs",
        "outputId": "808c5213-8439-4de4-f0d3-7de988e1e588"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-17 15:44:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/megatron/core/tensor_parallel/layers.py:220: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "      def forward(ctx, input, weight, bias, gradient_accumulation_fusion,\n",
            "    \n",
            "[NeMo W 2024-11-17 15:44:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/megatron/core/tensor_parallel/layers.py:250: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "      def backward(ctx, grad_output):\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "eIn8wXT3yd5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import torch\n",
        "import torchaudio\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import numpy as np\n",
        "import datetime\n",
        "from typing import List, Dict\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class SandalwoodQASystem:\n",
        "    def __init__(self, csv_path, kannada_asr_path):\n",
        "        \"\"\"\n",
        "        Initialize the QA system for Sandalwood news with text and audio capabilities.\n",
        "\n",
        "        Args:\n",
        "            csv_path: Path to the CSV file containing transcripts and translations\n",
        "            kannada_asr_path: Path to the Kannada ASR model\n",
        "        \"\"\"\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Initialize Kannada ASR model\n",
        "        self.kannada_asr = nemo_asr.models.EncDecCTCModel.restore_from(\n",
        "            restore_path=kannada_asr_path\n",
        "        )\n",
        "        self.kannada_asr.freeze()\n",
        "        self.kannada_asr = self.kannada_asr.to(self.device)\n",
        "\n",
        "        # Initialize translator\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD7eJyGM-Twi4Z-XUVdvJ_rGnPcJcFbgR8\"\n",
        "        self.translator = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "\n",
        "        # Initialize RAG components\n",
        "        self.initialize_rag_system(csv_path)\n",
        "\n",
        "        # Audio parameters\n",
        "        self.sample_rate = 16000\n",
        "        self.recording_duration = 10  # seconds\n",
        "\n",
        "        # Load and cache translations\n",
        "        self.audio_translations = {}\n",
        "        self.load_translations(csv_path)\n",
        "\n",
        "    def initialize_rag_system(self, csv_path: str):\n",
        "        try:\n",
        "            # Read CSV file\n",
        "            df = pd.read_csv(csv_path)\n",
        "\n",
        "            # Prepare documents for embedding\n",
        "            documents = []\n",
        "            for _, row in df.iterrows():\n",
        "                doc_content = {\n",
        "                    'source': row['audio_file'],\n",
        "                    'content': {\n",
        "                        'english': row['full_transcript_translation'],  # Changed from english_translation\n",
        "                        'kannada': row['full_transcript'],             # Changed from kannada_transcript\n",
        "                        'time_aligned': {\n",
        "                            'english': row['time_aligned_translations'],  # Changed from time_aligned_english\n",
        "                            'kannada': row['time_aligned_transcripts']   # Changed from time_aligned_kannada\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "                documents.append(str(doc_content))\n",
        "\n",
        "            # Initialize text splitter\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=1000,\n",
        "                chunk_overlap=200,\n",
        "                length_function=len\n",
        "            )\n",
        "\n",
        "            # Split documents\n",
        "            texts = text_splitter.create_documents(documents)\n",
        "\n",
        "            # Initialize embeddings\n",
        "            embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        "            )\n",
        "\n",
        "            # Create vector store\n",
        "            self.vector_store = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing RAG system: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def load_translations(self, csv_path: str):\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            for _, row in df.iterrows():\n",
        "                audio_file = os.path.basename(row['audio_file'])\n",
        "                self.audio_translations[audio_file] = {\n",
        "                    'content': {\n",
        "                        'english': row['full_transcript_translation'],  # Changed from english_translation\n",
        "                        'kannada': row['full_transcript'],             # Changed from kannada_transcript\n",
        "                        'time_aligned': {\n",
        "                            'english': row['time_aligned_translations'],  # Changed from time_aligned_english\n",
        "                            'kannada': row['time_aligned_transcripts']   # Changed from time_aligned_kannada\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading translations: {str(e)}\")\n",
        "\n",
        "    def get_audio_translation(self, audio_filename: str) -> Dict:\n",
        "        \"\"\"Get translation for an audio file if it exists.\"\"\"\n",
        "        return self.audio_translations.get(audio_filename, None)\n",
        "\n",
        "    def _is_kannada(self, text: str) -> bool:\n",
        "        \"\"\"Check if text contains Kannada characters.\"\"\"\n",
        "        kannada_range = range(0x0C80, 0x0CFF + 1)\n",
        "        return any(ord(char) in kannada_range for char in text)\n",
        "\n",
        "    def translate_to_english(self, kannada_text: str) -> str:\n",
        "        \"\"\"Translate Kannada text to English using Google's Gemini model.\"\"\"\n",
        "        try:\n",
        "            response = self.translator.invoke(\n",
        "                f\"Translate the following Kannada text to English: {kannada_text}\"\n",
        "            )\n",
        "            return response.content\n",
        "        except Exception as e:\n",
        "            print(f\"Error in translation: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def transcribe_audio(self, audio_path: str) -> str:\n",
        "        \"\"\"Transcribe Kannada audio to text using NeMo ASR model.\"\"\"\n",
        "        try:\n",
        "            # Load and preprocess audio\n",
        "            audio, sample_rate = sf.read(audio_path, dtype='float64')  # Specify dtype as float64/double\n",
        "\n",
        "            # Resample if necessary\n",
        "            if sample_rate != self.sample_rate:\n",
        "                resampler = torchaudio.transforms.Resample(\n",
        "                    orig_freq=sample_rate,\n",
        "                    new_freq=self.sample_rate\n",
        "                )\n",
        "                audio = resampler(torch.tensor(audio, dtype=torch.float64)).numpy()\n",
        "\n",
        "            # Convert to single channel if stereo\n",
        "            if len(audio.shape) > 1:\n",
        "                audio = audio.mean(axis=1)\n",
        "\n",
        "            # Ensure audio is in the correct format for NeMo\n",
        "            audio = audio.astype('float64')\n",
        "\n",
        "            # Transcribe\n",
        "            with torch.no_grad():\n",
        "                transcription = self.kannada_asr.transcribe(\n",
        "                    paths2audio_files=[audio_path]\n",
        "                )[0]\n",
        "\n",
        "            return transcription\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribing audio: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def record_audio_colab(self):\n",
        "        \"\"\"Record audio using Colab's audio recorder widget.\"\"\"\n",
        "        try:\n",
        "            # Create recordings directory if it doesn't exist\n",
        "            os.makedirs(\"recordings\", exist_ok=True)\n",
        "\n",
        "            # Generate unique filename\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            output_path = f\"recordings/recording_{timestamp}.wav\"\n",
        "\n",
        "            print(\"Recording... Click the microphone icon below to start/stop recording\")\n",
        "\n",
        "            # Display audio recorder widget\n",
        "            audio_recorder = output.eval_js('''\n",
        "                new Promise((resolve) => {\n",
        "                    const recorder = new AudioRecorder();\n",
        "                    recorder.start()\n",
        "                        .then(() => {\n",
        "                            setTimeout(() => {\n",
        "                                recorder.stop()\n",
        "                                    .then(audio => resolve(audio));\n",
        "                            }, 10000);  // 10 seconds recording\n",
        "                        });\n",
        "                });\n",
        "            ''')\n",
        "\n",
        "            if audio_recorder:\n",
        "                # Save the recorded audio\n",
        "                audio_data = np.frombuffer(audio_recorder, dtype=np.float32)\n",
        "                sf.write(output_path, audio_data, self.sample_rate)\n",
        "                print(\"\\nRecording saved successfully!\")\n",
        "                return output_path\n",
        "            else:\n",
        "                print(\"\\nNo audio recorded\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error recording audio: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def extract_time_range(self, time_aligned_str):\n",
        "        \"\"\"Extract time range from time-aligned transcript string.\"\"\"\n",
        "        try:\n",
        "            # Assuming format like \"[0:00-0:30] text [0:31-1:00] text\"\n",
        "            first_time = time_aligned_str.split(']')[0].strip('[')\n",
        "            last_time = time_aligned_str.split('[')[-1].split(']')[0]\n",
        "            return f\"{first_time}-{last_time}\"\n",
        "        except:\n",
        "            return \"00:00-00:00\"\n",
        "\n",
        "    def extract_audio_segment(self, audio_file: str, time_range: str) -> str:\n",
        "        \"\"\"Extract audio segment based on time range and save to file.\"\"\"\n",
        "        try:\n",
        "            # Create extracted_audio directory if it doesn't exist\n",
        "            os.makedirs(\"extracted_audio\", exist_ok=True)\n",
        "\n",
        "            # Generate output filename\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            output_path = f\"extracted_audio/segment_{timestamp}.wav\"\n",
        "\n",
        "            # Parse time range\n",
        "            start_time, end_time = time_range.split('-')\n",
        "            start_seconds = sum(float(x) * 60 ** i for i, x in enumerate(reversed(start_time.split(':'))))\n",
        "            end_seconds = sum(float(x) * 60 ** i for i, x in enumerate(reversed(end_time.split(':'))))\n",
        "\n",
        "            # Read audio file\n",
        "            data, samplerate = sf.read(audio_file)\n",
        "\n",
        "            # Extract segment\n",
        "            start_frame = int(start_seconds * samplerate)\n",
        "            end_frame = int(end_seconds * samplerate)\n",
        "            segment = data[start_frame:end_frame]\n",
        "\n",
        "            # Save segment\n",
        "            sf.write(output_path, segment, samplerate)\n",
        "\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting audio segment: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def answer_question(self, question, k=3):\n",
        "        \"\"\"Get answer using RAG system.\"\"\"\n",
        "        try:\n",
        "            # Get relevant documents\n",
        "            docs = self.vector_store.similarity_search(question, k=k)\n",
        "            results = []\n",
        "\n",
        "            for doc in docs:\n",
        "                try:\n",
        "                    # Safely parse the content back into dictionary\n",
        "                    content_str = doc.page_content.replace(\"'\", '\"')  # Replace single quotes with double quotes\n",
        "                    content = eval(content_str)\n",
        "\n",
        "                    # Extract time range from time-aligned transcripts\n",
        "                    time_range = self.extract_time_range(content['content']['time_aligned']['english'])\n",
        "\n",
        "                    # Extract audio segment\n",
        "                    extracted_audio_path = self.extract_audio_segment(content['source'], time_range)\n",
        "\n",
        "                    # Calculate simple relevance score based on content overlap\n",
        "                    question_words = set(question.lower().split())\n",
        "                    content_words = set(content['content']['english'].lower().split())\n",
        "                    relevance_score = len(question_words.intersection(content_words)) / len(question_words) if question_words else 0\n",
        "\n",
        "                    result = {\n",
        "                        'relevance_score': relevance_score,\n",
        "                        'audio_file': content['source'],\n",
        "                        'time_range': time_range,\n",
        "                        'english_translation': content['content']['english'],\n",
        "                        'original_kannada': content['content']['kannada'],\n",
        "                        'extracted_audio_path': extracted_audio_path\n",
        "                    }\n",
        "                    results.append(result)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing document: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Sort results by relevance score\n",
        "            results.sort(key=lambda x: x['relevance_score'], reverse=True)\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting answer: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def print_results(self, results: List[Dict]):\n",
        "        \"\"\"Print results in a formatted way.\"\"\"\n",
        "        if not results:\n",
        "            print(\"\\nNo relevant passages found.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\nRelevant passages found (ranked by relevance):\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            print(f\"\\nPassage {i} (Relevance Score: {result['relevance_score']:.3f}):\")\n",
        "            print(f\"Audio File: {result['audio_file']}\")\n",
        "            print(f\"Time Range: {result['time_range']}\")\n",
        "            print(f\"English Translation: {result['english_translation']}\")\n",
        "            print(f\"Original Kannada: {result['original_kannada']}\")\n",
        "            print(f\"Extracted Audio: {result['extracted_audio_path']}\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            # Play extracted audio if available\n",
        "            if result['extracted_audio_path']:\n",
        "                display(Audio(result['extracted_audio_path']))\n",
        "\n",
        "    def process_input(self, input_type='text', input_content=None):\n",
        "        try:\n",
        "            english_question = None\n",
        "\n",
        "            if input_type == 'text':\n",
        "                if not input_content:\n",
        "                    raise ValueError(\"No text input provided\")\n",
        "                if self._is_kannada(input_content):\n",
        "                    english_question = self.translate_to_english(input_content)\n",
        "                else:\n",
        "                    english_question = input_content\n",
        "\n",
        "            elif input_type == 'audio_file':\n",
        "                if not input_content or not os.path.exists(input_content):\n",
        "                    raise ValueError(\"Invalid audio file path\")\n",
        "\n",
        "                audio_filename = os.path.basename(input_content)\n",
        "                existing_translation = self.get_audio_translation(audio_filename)\n",
        "\n",
        "                if existing_translation:\n",
        "                    english_question = existing_translation['content']['english']\n",
        "                else:\n",
        "                    kannada_text = self.transcribe_audio(input_content)\n",
        "                    if not kannada_text:\n",
        "                        raise ValueError(\"Failed to transcribe audio\")\n",
        "                    english_question = self.translate_to_english(kannada_text)\n",
        "\n",
        "            elif input_type == 'speech':\n",
        "                audio_path = self.record_audio_colab()\n",
        "                if audio_path:\n",
        "                    kannada_text = self.transcribe_audio(audio_path)\n",
        "                    if not kannada_text:\n",
        "                        raise ValueError(\"Failed to transcribe speech\")\n",
        "                    english_question = self.translate_to_english(kannada_text)\n",
        "                    os.remove(audio_path)  # Clean up recording\n",
        "                else:\n",
        "                    raise ValueError(\"No audio recorded\")\n",
        "\n",
        "            if not english_question:\n",
        "                raise ValueError(\"Failed to process input\")\n",
        "\n",
        "            results = self.answer_question(english_question)\n",
        "            if not results:\n",
        "                print(\"No relevant information found for your query.\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing input: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def start_qa_session(self):\n",
        "        \"\"\"Start an interactive QA session.\"\"\"\n",
        "        print(\"\\nWelcome to the Sandalwood News QA System!\")\n",
        "        print(\"You can:\")\n",
        "        print(\"1. Type your question (English or Kannada)\")\n",
        "        print(\"2. Provide an audio file path\")\n",
        "        print(\"3. Speak your question (using Colab's audio recorder)\")\n",
        "        print(\"Type 'quit' to exit\")\n",
        "\n",
        "        while True:\n",
        "            print(\"\\nChoose input method:\")\n",
        "            print(\"1. Text\")\n",
        "            print(\"2. Audio File\")\n",
        "            print(\"3. Speech\")\n",
        "            choice = input(\"Enter choice (1-3): \")\n",
        "\n",
        "            if choice.lower() == 'quit':\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                if choice == '1':\n",
        "                    question = input(\"\\nEnter your question: \")\n",
        "                    if question.lower() == 'quit':\n",
        "                        break\n",
        "                    results = self.process_input('text', question)\n",
        "\n",
        "                elif choice == '2':\n",
        "                    audio_path = input(\"\\nEnter audio file path: \")\n",
        "                    if audio_path.lower() == 'quit':\n",
        "                        break\n",
        "                    results = self.process_input('audio_file', audio_path)\n",
        "\n",
        "                elif choice == '3':\n",
        "                    print(\"\\nPreparing audio recorder...\")\n",
        "                    results = self.process_input('speech')\n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid choice!\")\n",
        "                    continue\n",
        "\n",
        "                self.print_results(results)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define paths to required files\n",
        "    csv_path = \"/content/allfilescombined.csv\"\n",
        "    kannada_asr_path = '/content/ai4b_indicConformer_kn.nemo'\n",
        "\n",
        "    try:\n",
        "        # Initialize the QA system\n",
        "        print(\"Initializing Sandalwood QA System...\")\n",
        "        qa_system = SandalwoodQASystem(csv_path, kannada_asr_path)\n",
        "\n",
        "        # Start interactive session\n",
        "        print(\"\\nSystem initialized successfully!\")\n",
        "        print(\"Starting interactive QA session...\")\n",
        "        qa_system.start_qa_session()\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: Required file not found - {str(e)}\")\n",
        "        print(\"Please ensure both the CSV file and Kannada ASR model are in the correct locations.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing QA system: {str(e)}\")\n",
        "        print(\"Please check your configuration and try again.\")\n",
        "\n",
        "    finally:\n",
        "        print(\"\\nThank you for using the Sandalwood QA System!\")"
      ],
      "metadata": {
        "id": "aLRVpUrY0DyE",
        "outputId": "474052e5-2ef0-4b0b-c398-55275615cbfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Sandalwood QA System...\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:198] _setup_tokenizer: detected an aggregate tokenizer\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:10:43 multilingual_tokenizer:61] Aggregate vocab size: 5632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-17 16:10:51 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/train/train_kannada.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    max_duration: 30.0\n",
            "    min_duration: 0.2\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    shuffle_n: 2048\n",
            "    bucketing_strategy: synced_randomized\n",
            "    bucketing_batch_size: null\n",
            "    is_concat: true\n",
            "    concat_sampling_technique: temperature\n",
            "    concat_sampling_temperature: 1.5\n",
            "    return_language_id: true\n",
            "    \n",
            "[NeMo W 2024-11-17 16:10:51 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/valid_datasetwise/valid_kannada_indicvoices.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    return_language_id: true\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-17 16:10:51 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-17 16:10:51 features:289] PADDING: 0\n",
            "[NeMo I 2024-11-17 16:10:54 rnnt:1663] Vocab size for each language: 256\n",
            "[NeMo I 2024-11-17 16:10:54 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:10:54 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:10:55 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:10:55 hybrid_rnnt_ctc_bpe_models:105] Creating masks for multi-softmax layer.\n",
            "[NeMo I 2024-11-17 16:10:55 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:10:56 save_restore_connector:263] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /content/ai4b_indicConformer_kn.nemo.\n",
            "\n",
            "System initialized successfully!\n",
            "Starting interactive QA session...\n",
            "\n",
            "Welcome to the Sandalwood News QA System!\n",
            "You can:\n",
            "1. Type your question (English or Kannada)\n",
            "2. Provide an audio file path\n",
            "3. Speak your question (using Colab's audio recorder)\n",
            "Type 'quit' to exit\n",
            "\n",
            "Choose input method:\n",
            "1. Text\n",
            "2. Audio File\n",
            "3. Speech\n",
            "Enter choice (1-3): 1\n",
            "\n",
            "Enter your question: What is mentioned about the farmers\n",
            "Error processing document: invalid syntax (<string>, line 1)\n",
            "Error processing document: unterminated string literal (detected at line 1) (<string>, line 1)\n",
            "Error processing document: unmatched ']' (<string>, line 1)\n",
            "No relevant information found for your query.\n",
            "\n",
            "No relevant passages found.\n",
            "\n",
            "Choose input method:\n",
            "1. Text\n",
            "2. Audio File\n",
            "3. Speech\n",
            "Enter choice (1-3): quit\n",
            "\n",
            "Thank you for using the Sandalwood QA System!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def load_and_prepare_data(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "    df['time_aligned_transcripts'] = df['time_aligned_transcripts'].apply(ast.literal_eval)\n",
        "    df['time_aligned_translations'] = df['time_aligned_translations'].apply(ast.literal_eval)\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_documents(df):\n",
        "    documents = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "\n",
        "        for time_range, translation in row['time_aligned_translations'].items():\n",
        "\n",
        "            metadata = {\n",
        "                'audio_file': row['audio_file'],\n",
        "                'time_range': time_range,\n",
        "                'original_text': row['time_aligned_transcripts'].get(time_range, ''),\n",
        "                'full_translation': row['full_transcript_translation']\n",
        "            }\n",
        "\n",
        "            doc = Document(\n",
        "                page_content=translation,\n",
        "                metadata=metadata\n",
        "            )\n",
        "            documents.append(doc)\n",
        "\n",
        "    return documents\n",
        "\n",
        "# Initialize vector store\n",
        "def initialize_vector_store(documents):\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "    )\n",
        "\n",
        "    # Create FAISS index\n",
        "    vector_store = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "def answer_question(question, vector_store, k=3):\n",
        "    docs = vector_store.similarity_search(question, k=k)\n",
        "\n",
        "    print(\"\\nRelevant passages found:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        print(f\"\\nPassage {i}:\")\n",
        "        print(f\"Audio File: {doc.metadata['audio_file']}\")\n",
        "        print(f\"Time Range: {doc.metadata['time_range']}\")\n",
        "        print(f\"English Translation: {doc.page_content}\")\n",
        "        print(f\"Original Kannada: {doc.metadata['original_text']}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    return docs\n",
        "\n",
        "def setup_qa_system(csv_path):\n",
        "    print(\"Loading data...\")\n",
        "    df = load_and_prepare_data(csv_path)\n",
        "\n",
        "    print(\"Creating documents...\")\n",
        "    documents = create_documents(df)\n",
        "\n",
        "    print(\"Initializing vector store...\")\n",
        "    vector_store = initialize_vector_store(documents)\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    csv_path = \"/content/allfilescombined.csv\"\n",
        "    vector_store = setup_qa_system(csv_path)\n",
        "\n",
        "    print(\"\\nWelcome to the Q&A System!\")\n",
        "    print(\"Type 'quit' or 'exit' to end the session\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nEnter your question: \").strip()\n",
        "\n",
        "        if question.lower() in ['quit', 'exit']:\n",
        "            print(\"Thank you for using the Q&A system. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not question:\n",
        "            print(\"Please enter a valid question.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nSearching for answer to: {question}\")\n",
        "        relevant_docs = answer_question(question, vector_store)"
      ],
      "metadata": {
        "id": "vPXI-XJY5RHf",
        "outputId": "307ccaf0-7a5e-4511-914b-7ebcd88754ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9d5cec7e7d534175a0c15cd623d59312",
            "a201b986ea7c45b2b94ce1a13d2520de",
            "c616727da4f14332b4b9eb81f5d84b11",
            "a9ce8d6c1aad4d9897c69017b8999737",
            "f8eb286a02d74fdd9145cbd1693f688a",
            "d9081a39aa6c4f2f950daffc6856aae3",
            "c6523878d0724703a0a05c7cdc7c8858",
            "0a89ee5d4852480da7baf4a118b0e0fa",
            "2bde9696f44b4237b1231245ae7e05bc",
            "e64f84ec9a0c41ad82f7fe1dfd7d80d7",
            "22f3d22c36e34f5f813c33f8e072909a",
            "4a5deab07b3d497db0202365a8c29251",
            "6deb564efb974435b78c6caea029727b",
            "ff7804d0a45048bd8e41aecb4e22909c",
            "087aeedfd67e43039bdb2f2865cdb361",
            "a458e740123b4c209598902c7aa0b005",
            "8e764c15d5e74b1c91e4d8a60f2ac4fe",
            "929a815731104380bac684351d13d14a",
            "99fe196e56e64b128b8373b6c43a91b6",
            "97d310bcdce54a40af9e68f1233b0033",
            "156bef3068344d46a2aee3b2fce6644b",
            "4766519ffafb4c9699843ee8acb66530",
            "4e64adb5d69f4762b3fcdebd642dd8dc",
            "4e230071982d4960ab60c7a0965dd988",
            "6b1515cc16ad476eb6b7e5300ebf8a95",
            "f8dd8224d68b4dcdbee2270346188756",
            "e4b81d1241be4c3f9b26f6d7e36c71f0",
            "551a58f3370449de80c7559f4a3824bd",
            "b7e9a1b8a6b14aa5b271cd7abb45dc1b",
            "ed81e98ebb2b4586a6bb5b88f84f2a44",
            "be0f7b2d9799404a878918a661766cc8",
            "f07762d084374e03a58b4465b49fa36a",
            "c1c4ddf20de04f1eb356707513a50962",
            "6cd7c63c12294326856adf379b6e6471",
            "2de5b9afc9464ab486b28948a422989a",
            "db5f2e4cccdf4ed8b3707c4469806654",
            "36f86afce6c045f2b873ae32e59adae8",
            "e6cd5ef4ec304b9d861d5918280aecdb",
            "8d9719a825224b79963ba61fb8fb5d44",
            "69bdd9074776494080dca2ebcd203938",
            "f4d0f3a0845044b8828098d9db080327",
            "e963f1b0e2c644deb3fdfe2ac8e2ffef",
            "b0c896a88b7240fda586d08aa80b3bad",
            "8a96a1af16fc4aa496031e20f6e31992",
            "e7f5323f66804e93a8f0bf06c283ade4",
            "8b12e093025f4424bad813e69b9158f4",
            "53c787c47a7d491c953ef068e6d41617",
            "608c5f57004c4f789e312bc2aad602aa",
            "92d2a6a498de4d91aee8d6c476e0f60d",
            "4119417cc9ed4b4797e8f194bf6311bf",
            "ac630682054643c4915f11e541599d93",
            "e2d1f6f9274c421eb8f85a282bf2fd8b",
            "3cd4b40ae3d14d67b958229f28b53ca4",
            "fde63035fc3d4e8cab5dd2a78bf70679",
            "385d41cf513b4055aa06056df91d433a",
            "ac3724e53cce4630875216763c143b2d",
            "8c962bc1e0834828af08a43a21ecae28",
            "0017a49109fe4e6bb1594753b58923d9",
            "ddfd30f852c54b68838d8d04b08bb16d",
            "a94e4ac017224ee4b8325aed5321d45a",
            "3de265818e5747aa9179b0762044b37a",
            "6475edff589247bb8b6ae1bfe107f658",
            "213e1fd9ebce41f490d7acdd3f0d803e",
            "36a93e23c2314b39b4c7bf705768fdee",
            "ffa072257a304fc6bac003afaff66647",
            "60c28a3ef3db4817a167f2d26f1b2985",
            "1323956e26144970a48bc9e9039d98a9",
            "730fd74a5607435e9abd5bff210a8106",
            "e763404af11142138d3843a088ea57f5",
            "8754f0d524cf47ada05ac24af2f11c74",
            "2b2d84f0932e42e8a0b870e5e4446fc5",
            "a536079d6e7a4720ad2af88a48119eab",
            "0d294214ec784d68982ba1f3e2c4a6fb",
            "872aa787ad2440c6bc9e71f8fe73b2ab",
            "18114fe70f3048e48f9f777a17d765e6",
            "03600ee58aec4404a6ca94db7ba030a0",
            "bf4a8de70de544dda42085830fcde231",
            "c223292075ac45f4abf68e0de5735f25",
            "8dbc62c0b50945b4b042b74d8ea40edb",
            "0b8550d8ab9c4eb384b192fa55a6e076",
            "5bc104c4252148a5aa700f27054127dc",
            "251463becaeb4071b5f3158d5d8f13d8",
            "e4bcee068691487caf612320e7f913c3",
            "6759311903b94ec5aced9ff5ec0e3953",
            "7df0d9897eaf42478ca0058d547dabfb",
            "237a60ac2fa9485ea3319b925c2e2c87",
            "602b4c80fea54d51b8622d0f78185c57",
            "5ecc2660a24b4627896fb14872e5809f",
            "f2e7414353a949709d343af7e2f10603",
            "9c4ab88c94184f51bf62e9d2012b26ca",
            "e5a8853a3f5f4183a1f3083cf8d4fd88",
            "02883d5580ac4da4a1d17c4892275bd6",
            "75507e538444493cb9a695e6343a8b88",
            "593230fae8ce44909361ecdc94e50ccd",
            "8b2cafccf6d54d4bb7b0e8e1753c22a3",
            "e2692f8540634cc881ae502fedf0551a",
            "859befbbe54c43ebb2600dbb67bf2bca",
            "91eda1bf255844f0bcc60cd7902a3b2d",
            "0e17942600dd455b9e49af6b7c3fab2d",
            "30452802d39e4b46897ee93bdf138b23",
            "52af2fc074ab44a0967b32664b95dd6a",
            "543d21e7648e4d7db0a60f81dfa33283",
            "8fc0f8f36c4f4220ad655076eaacfcf6",
            "25cbacccb3ab4a61a2e60383b4e6872d",
            "fb613cfd254a42529bc3dd61f4c69daa",
            "2c54d25b6a0545c29a35be9759130c3d",
            "37d2472730c44f4ea5329714c2ac6e6b",
            "170303c47577423fbdcc945edf8b1f8d",
            "b0d47555e4fe48c0b0ecc048f267623a",
            "160ba692be0c4e1cb3e26f7470bb041e",
            "137841e89e5144a49a9472d12f04516f",
            "eae1513489b1490cb08b5b1122945191",
            "8a5179270dbd4ec39d13f0b66fb516af",
            "a0f1884c9fa446d8b5bb263897a5a94d",
            "1be378f2746b40b8a187ecd1515eb3bf",
            "185238e69f3648c9b10385f6a55a68f8",
            "5e8b3e59c98a423b8746bf34fc07ea28",
            "6cea3dbededa4f35b8a3aa981904dc1b",
            "9f5e47ea836f43d29e5b45f8ed0bb482",
            "322ba9efa5c44f88adb7b136d6eaa8a6",
            "a98f09813f714e818d27d648cd16bbe7"
          ]
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Creating documents...\n",
            "Initializing vector store...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d5cec7e7d534175a0c15cd623d59312"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a5deab07b3d497db0202365a8c29251"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.13k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e64adb5d69f4762b3fcdebd642dd8dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cd7c63c12294326856adf379b6e6471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7f5323f66804e93a8f0bf06c283ade4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac3724e53cce4630875216763c143b2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1323956e26144970a48bc9e9039d98a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c223292075ac45f4abf68e0de5735f25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2e7414353a949709d343af7e2f10603"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30452802d39e4b46897ee93bdf138b23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "137841e89e5144a49a9472d12f04516f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Welcome to the Q&A System!\n",
            "Type 'quit' or 'exit' to end the session\n",
            "\n",
            "Enter your question: What is mentioned about farmers?\n",
            "\n",
            "Searching for answer to: What is mentioned about farmers?\n",
            "\n",
            "Relevant passages found:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Passage 1:\n",
            "Audio File: SandalWoodNewsStories_156.mp3\n",
            "Time Range: 290.00s - 300.00s\n",
            "English Translation: ([Farmers are tilling the soil and doing all the ploughing and sowing in the agricultural land.], [Farmers are tilling the soil and doing all the ploughing and sowing in the agricultural land.])\n",
            "Original Kannada: ([' ಫಾರ್ಮರ್ಸ್ ಆಗ್ರಿಕಲ್ಚರ ಲಂಡ್ ಅಲ್ಲಿ ಫೂಲ ಉಳುಮೆ ಮಾಡ್ಕೊಂಡು ಪ್ಲೋಇಂಗ್ ಎಲ್ಲ ಮಾಡಿ ನೆಟ್ಬೋದು ಆ'], [' ಫಾರ್ಮರ್ಸ್ ಆಗ್ರಿಕಲ್ಚರ ಲಂಡ್ ಅಲ್ಲಿ ಫೂಲ ಉಳುಮೆ ಮಾಡ್ಕೊಂಡು ಪ್ಲೋಇಂಗ್ ಎಲ್ಲ ಮಾಡಿ ನೆಟ್ಬೋದು ಆ'])\n",
            "----------------------------------------\n",
            "\n",
            "Passage 2:\n",
            "Audio File: SandalWoodNewsStories_42.mp3\n",
            "Time Range: 900.00s - 910.00s\n",
            "English Translation: ([' Farmers' Own '], [' Farmers' Own '])\n",
            "Original Kannada: ([' ರೈತಾ್ ಯ ಅ ಆದ ಬ'], [' ರೈತಾ್ ಯ ಅ ಆದ ಬ'])\n",
            "----------------------------------------\n",
            "\n",
            "Passage 3:\n",
            "Audio File: SandalWoodNewsStories_169.mp3\n",
            "Time Range: 510.00s - 520.00s\n",
            "English Translation: ([ ' Different experts in this subject, farmers who have grown crops will give us information by them ' ], [ ' Different experts in this subject, farmers who have grown crops will give us information by them ' ])\n",
            "Original Kannada: ([' ಬೇರೆ ಬೇರೆ ಈ ವಿಷಯ ತಜ್ಞರು ಇವರು ಬೆಳೆದಿರೋಂಥ ಬೆಳೆಗಾರರು ನಮಗೆ ಮಾಹಿತಿ ತಿಳಿಸಿರ್ತಾರೆ ಅವರಿಂದ'], [' ಬೇರೆ ಬೇರೆ ಈ ವಿಷಯ ತಜ್ಞರು ಇವರು ಬೆಳೆದಿರೋಂಥ ಬೆಳೆಗಾರರು ನಮಗೆ ಮಾಹಿತಿ ತಿಳಿಸಿರ್ತಾರೆ ಅವರಿಂದ'])\n",
            "----------------------------------------\n",
            "\n",
            "Enter your question: Is there any mention about government schemes?\n",
            "\n",
            "Searching for answer to: Is there any mention about government schemes?\n",
            "\n",
            "Relevant passages found:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Passage 1:\n",
            "Audio File: SandalWoodNewsStories_176.mp3\n",
            "Time Range: 1040.00s - 1050.00s\n",
            "English Translation: ([' Look, our government is providing so many schemes. Farmers are not using the government schemes. There are so many schemes. I have brochures of all the departments of the forest'], [' Look, our government is providing so many schemes. Farmers are not using the government schemes. There are so many schemes. I have brochures of all the departments of the forest'])\n",
            "Original Kannada: ([' ನೋಡಿ ಅರಣ್ಯ ನಮ್ಮ ಸರ್ಕಾರ ಸುಮಾರು ಸ್ಕೀಮ್ಗಳು ಕೊಡ್ತಾ ಇದೆ ಸರ್ಕಾರದ ಸ್ಕೀಮ್ ಗಳನ್ನ ರೈತರು ಬಳಸ್ಕೊತ ಇಲ್ಲಪ್ಪ ಸುಮಾರು ಸ್ಕೀಮ್ ಗಳಿದ್ದಾವೆ ನನ್ನತ್ತ ಸುಮಾರು ಅರಣ್ಯ ಎಲ್ಲಾ ಡಿಪಾರ್ಟ್ಮೆಂಟ್ ಬ್ರೋ ಚರ್ಸ್ ಇದ್ದಾವೆ'], [' ನೋಡಿ ಅರಣ್ಯ ನಮ್ಮ ಸರ್ಕಾರ ಸುಮಾರು ಸ್ಕೀಮ್ಗಳು ಕೊಡ್ತಾ ಇದೆ ಸರ್ಕಾರದ ಸ್ಕೀಮ್ ಗಳನ್ನ ರೈತರು ಬಳಸ್ಕೊತ ಇಲ್ಲಪ್ಪ ಸುಮಾರು ಸ್ಕೀಮ್ ಗಳಿದ್ದಾವೆ ನನ್ನತ್ತ ಸುಮಾರು ಅರಣ್ಯ ಎಲ್ಲಾ ಡಿಪಾರ್ಟ್ಮೆಂಟ್ ಬ್ರೋ ಚರ್ಸ್ ಇದ್ದಾವೆ'])\n",
            "----------------------------------------\n",
            "\n",
            "Passage 2:\n",
            "Audio File: SandalWoodNewsStories_169.mp3\n",
            "Time Range: 810.00s - 820.00s\n",
            "English Translation: ([Steve says it is very expensive. He says that since it is in the initial stage, it will be expensive. Let's see, government], [Steve says it is very expensive. He says that since it is in the initial stage, it will be expensive. Let's see, government])\n",
            "Original Kannada: (['ಸ್್ತೀವಿ ಅಂತೇಳಿ ಹೇಳ್ತಾಯಿದ್ದಾರೆ ಅದು ತುಂಬ ದುಬಾರಿ ಅಂಂತೇಳಿ ಇನ್ನೂ ಅದನ್ನು ಪ್ರಾರಂಭಿಕ ಹಂತದಲ್ಲಿದೆ ದುಬಾರಿ ಆಗ್ತದೆ ಅಂತೇಳಿ ಹೇಳಿದ್ದಾರೆ ನೋಡೋಣ ಸರ್ಕಾರ'], ['ಸ್್ತೀವಿ ಅಂತೇಳಿ ಹೇಳ್ತಾಯಿದ್ದಾರೆ ಅದು ತುಂಬ ದುಬಾರಿ ಅಂಂತೇಳಿ ಇನ್ನೂ ಅದನ್ನು ಪ್ರಾರಂಭಿಕ ಹಂತದಲ್ಲಿದೆ ದುಬಾರಿ ಆಗ್ತದೆ ಅಂತೇಳಿ ಹೇಳಿದ್ದಾರೆ ನೋಡೋಣ ಸರ್ಕಾರ'])\n",
            "----------------------------------------\n",
            "\n",
            "Passage 3:\n",
            "Audio File: SandalWoodNewsStories_43.mp3\n",
            "Time Range: 260.00s - 270.00s\n",
            "English Translation: ([So basically I heard that the Karnataka Government is providing a lot of support now. Does every state have different rules or is it the same for all states?])\n",
            "Original Kannada: ([' ಸೋ ಬಸಿಕಾಲಿ ಇವಾಗ ಕರ್ನಾಟಕ ಗವರ್ನಮೆಂಟ್ನು ತುಂಬಾ ಸುಪ್ಪೋರ್ಟ್ ಮಾಡ್ತಾ ಇದೆ ಅಂತ ಕೇಳಿದ್ವಿ ಇದು ಒಂದೊಂದು್ ಸ್ಟೇಟ್ ಗೆ ಒಂದೊಂದು್ ರುಲ್ಸ್ ಏನಾದ್ೂ ಇರುತ್ತೆ ಸಿರ ಇಲ್ಲ ಎಲ್ಲಾ ಸ್ಟೇಟ್ ಗೂ ಒಂದೇ'], [' ಸೋ ಬಸಿಕಾಲಿ ಇವಾಗ ಕರ್ನಾಟಕ ಗವರ್ನಮೆಂಟ್ನು ತುಂಬಾ ಸುಪ್ಪೋರ್ಟ್ ಮಾಡ್ತಾ ಇದೆ ಅಂತ ಕೇಳಿದ್ವಿ ಇದು ಒಂದೊಂದು್ ಸ್ಟೇಟ್ ಗೆ ಒಂದೊಂದು್ ರುಲ್ಸ್ ಏನಾದ್ೂ ಇರುತ್ತೆ ಸಿರ ಇಲ್ಲ ಎಲ್ಲಾ ಸ್ಟೇಟ್ ಗೂ ಒಂದೇ'])\n",
            "----------------------------------------\n",
            "\n",
            "Enter your question: quit\n",
            "Thank you for using the Q&A system. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from pydub import AudioSegment\n",
        "import ast\n",
        "import re\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class AudioRAGSystem:\n",
        "    def __init__(self, csv_path: str, audio_dir: str, output_dir: str = \"./extracted_segments\"):\n",
        "        \"\"\"\n",
        "        Initialize the RAG system with paths for data and audio files.\n",
        "\n",
        "        Args:\n",
        "            csv_path: Path to the CSV file containing transcriptions and translations\n",
        "            audio_dir: Directory containing the audio files\n",
        "            output_dir: Directory to save extracted audio segments\n",
        "        \"\"\"\n",
        "        self.csv_path = csv_path\n",
        "        self.audio_dir = audio_dir\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Load data and initialize system\n",
        "        self.df = self.load_and_prepare_data()\n",
        "        self.documents = self.create_documents()\n",
        "        self.vector_store = self.initialize_vector_store()\n",
        "\n",
        "        # Cache for loaded audio files\n",
        "        self.audio_cache = {}\n",
        "\n",
        "    def parse_time(self, time_str: str) -> float:\n",
        "        \"\"\"\n",
        "        Parse time string to float, handling various formats.\n",
        "\n",
        "        Args:\n",
        "            time_str: Time string (e.g., \"0.00s\", \"0.00s \", \" 0.00s\", etc.)\n",
        "\n",
        "        Returns:\n",
        "            float: Time in seconds\n",
        "        \"\"\"\n",
        "        cleaned = time_str.strip().rstrip('s').strip()\n",
        "        return float(cleaned)\n",
        "\n",
        "    def load_and_prepare_data(self) -> pd.DataFrame:\n",
        "        \"\"\"Load and prepare the CSV data.\"\"\"\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "\n",
        "        def safe_eval(x):\n",
        "            try:\n",
        "                return ast.literal_eval(x) if isinstance(x, str) else x\n",
        "            except (ValueError, SyntaxError):\n",
        "                return {}\n",
        "\n",
        "        df['time_aligned_transcripts'] = df['time_aligned_transcripts'].apply(safe_eval)\n",
        "        df['time_aligned_translations'] = df['time_aligned_translations'].apply(safe_eval)\n",
        "        return df\n",
        "\n",
        "    def create_documents(self) -> List[Document]:\n",
        "        \"\"\"Create documents for vector store with merged time segments.\"\"\"\n",
        "        documents = []\n",
        "\n",
        "        for idx, row in self.df.iterrows():\n",
        "            try:\n",
        "\n",
        "                time_ranges = sorted(\n",
        "                    row['time_aligned_translations'].keys(),\n",
        "                    key=lambda x: self.parse_time(x.split('-')[0])\n",
        "                )\n",
        "\n",
        "                for i in range(len(time_ranges)):\n",
        "                    combined_text = \"\"\n",
        "                    combined_original = \"\"\n",
        "                    start_time = self.parse_time(time_ranges[i].split('-')[0])\n",
        "\n",
        "                    j = i\n",
        "                    while j < len(time_ranges):\n",
        "                        end_time = self.parse_time(time_ranges[j].split('-')[1])\n",
        "                        if end_time - start_time > 30:\n",
        "                            break\n",
        "\n",
        "                        current_translation = row['time_aligned_translations'].get(time_ranges[j], \"\")\n",
        "                        current_transcript = row['time_aligned_transcripts'].get(time_ranges[j], \"\")\n",
        "\n",
        "                        if current_translation:\n",
        "                            combined_text += \" \" + current_translation\n",
        "                        if current_transcript:\n",
        "                            combined_original += \" \" + current_transcript\n",
        "                        j += 1\n",
        "\n",
        "                    if not combined_text.strip() or not combined_original.strip():\n",
        "                        continue\n",
        "\n",
        "                    metadata = {\n",
        "                        'audio_file': row['audio_file'],\n",
        "                        'start_time': start_time,\n",
        "                        'end_time': end_time,\n",
        "                        'time_range': f\"{start_time:.2f}s - {end_time:.2f}s\",\n",
        "                        'original_text': combined_original.strip(),\n",
        "                        'full_translation': row.get('full_transcript_translation', '')\n",
        "                    }\n",
        "\n",
        "                    doc = Document(\n",
        "                        page_content=combined_text.strip(),\n",
        "                        metadata=metadata\n",
        "                    )\n",
        "                    documents.append(doc)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row {idx}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return documents\n",
        "\n",
        "    def initialize_vector_store(self) -> FAISS:\n",
        "        \"\"\"Initialize the FAISS vector store.\"\"\"\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "        )\n",
        "        return FAISS.from_documents(self.documents, embeddings)\n",
        "\n",
        "    def calculate_relevance_score(self, question: str, doc: Document) -> float:\n",
        "        \"\"\"\n",
        "        Calculate a relevance score for a document relative to the question.\n",
        "        Uses a combination of semantic similarity and keyword matching.\n",
        "        \"\"\"\n",
        "        try:\n",
        "\n",
        "            embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "            )\n",
        "            question_emb = embeddings.embed_query(question)\n",
        "            doc_emb = embeddings.embed_query(doc.page_content)\n",
        "\n",
        "            semantic_score = F.cosine_similarity(\n",
        "                torch.tensor(question_emb).unsqueeze(0),\n",
        "                torch.tensor(doc_emb).unsqueeze(0)\n",
        "            ).item()\n",
        "\n",
        "            question_words = set(question.lower().split())\n",
        "            doc_words = set(doc.page_content.lower().split())\n",
        "            keyword_score = len(question_words.intersection(doc_words)) / len(question_words)\n",
        "\n",
        "            final_score = 0.7 * semantic_score + 0.3 * keyword_score\n",
        "\n",
        "            return final_score\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating relevance score: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def extract_audio_segment(self, audio_file: str, start_time: float, end_time: float) -> str:\n",
        "        \"\"\"Extract and save an audio segment.\"\"\"\n",
        "        try:\n",
        "\n",
        "            if audio_file not in self.audio_cache:\n",
        "                audio_path = os.path.join(self.audio_dir, audio_file)\n",
        "                self.audio_cache[audio_file] = AudioSegment.from_mp3(audio_path)\n",
        "\n",
        "            audio = self.audio_cache[audio_file]\n",
        "\n",
        "            start_ms = int(start_time * 1000)\n",
        "            end_ms = int(end_time * 1000)\n",
        "\n",
        "            segment = audio[start_ms:end_ms]\n",
        "\n",
        "            output_filename = f\"segment_{audio_file}_{start_time:.2f}_{end_time:.2f}.mp3\"\n",
        "            output_path = os.path.join(self.output_dir, output_filename)\n",
        "            segment.export(output_path, format='mp3')\n",
        "\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting audio segment: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def answer_question(self, question: str, k: int = 5) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Answer a question by retrieving and ranking relevant passages.\n",
        "        Also extracts corresponding audio segments.\n",
        "        \"\"\"\n",
        "        try:\n",
        "\n",
        "            docs = self.vector_store.similarity_search(question, k=k)\n",
        "\n",
        "            scored_docs = [\n",
        "                (doc, self.calculate_relevance_score(question, doc))\n",
        "                for doc in docs\n",
        "            ]\n",
        "            scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            results = []\n",
        "            for doc, score in scored_docs:\n",
        "\n",
        "                audio_path = self.extract_audio_segment(\n",
        "                    doc.metadata['audio_file'],\n",
        "                    doc.metadata['start_time'],\n",
        "                    doc.metadata['end_time']\n",
        "                )\n",
        "\n",
        "                result = {\n",
        "                    'relevance_score': score,\n",
        "                    'audio_file': doc.metadata['audio_file'],\n",
        "                    'time_range': doc.metadata['time_range'],\n",
        "                    'english_translation': doc.page_content,\n",
        "                    'original_kannada': doc.metadata['original_text'],\n",
        "                    'extracted_audio_path': audio_path\n",
        "                }\n",
        "                results.append(result)\n",
        "\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"Error answering question: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def print_results(self, results: List[Dict]):\n",
        "        \"\"\"Print results in a formatted way.\"\"\"\n",
        "        if not results:\n",
        "            print(\"\\nNo relevant passages found.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\nRelevant passages found (ranked by relevance):\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            print(f\"\\nPassage {i} (Relevance Score: {result['relevance_score']:.3f}):\")\n",
        "            print(f\"Audio File: {result['audio_file']}\")\n",
        "            print(f\"Time Range: {result['time_range']}\")\n",
        "            print(f\"English Translation: {result['english_translation']}\")\n",
        "            print(f\"Original Kannada: {result['original_kannada']}\")\n",
        "            print(f\"Extracted Audio: {result['extracted_audio_path']}\")\n",
        "            print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "SeYqnCWc7ROD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "csv_path = \"/content/allfilescombined.csv\"\n",
        "audio_dir = \"/content/audio-kannada\"\n",
        "output_dir = \"/content/extracted_segments2\"\n",
        "\n",
        "rag_system = AudioRAGSystem(csv_path, audio_dir, output_dir)\n",
        "\n",
        "def interactive_qa():\n",
        "    while True:\n",
        "        question = input(\"\\nEnter your question (or 'quit' to exit): \")\n",
        "        if question.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        print(\"\\nSearching for answer...\")\n",
        "        results = rag_system.answer_question(question)\n",
        "        rag_system.print_results(results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    sample_question = \"What is mentioned about farmers?\"\n",
        "    results = rag_system.answer_question(sample_question)\n",
        "    rag_system.print_results(results)\n",
        "    print(\"\\nEntering interactive mode...\")\n",
        "    interactive_qa()"
      ],
      "metadata": {
        "id": "U75NvZKJ7UF2",
        "outputId": "bf9dce68-b66a-493a-d1fb-ae982ced88f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Relevant passages found (ranked by relevance):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Passage 1 (Relevance Score: 0.661):\n",
            "Audio File: SandalWoodNewsStories_9.mp3\n",
            "Time Range: 650.00s - 690.00s\n",
            "English Translation: ([My contact with farmers is continuous, different organizations come and hundreds of farmers come under one roof, they themselves come and gather there], [My contact with farmers is continuous, different organizations come and hundreds of farmers come under one roof, they themselves come and gather there]) ([' Every third Sunday of the month, we have a group discussion where farmers can discuss any confusions they have about agroforestry, what to do and not to do'], [' Every third Sunday of the month, we have a group discussion where farmers can discuss any confusions they have about agroforestry, what to do and not to do']) ([' And so what I do is every third Sunday of the month at 9 am, I have a session on agro forestry models on our farm'], [' And so what I do is every third Sunday of the month at 9 am, I have a session on agro forestry models on our farm'])\n",
            "Original Kannada: ([' ನಿರಂತರ ಇರ್ತದೆ ನನ್ನ ರೈತರ ಸಂಪರ್ಕ ಬೇರೆ ಬೇರೆ ಸಂಘ ಸಂಸ್ಥೆಗಳು ಬರ್ತಾ ಒಂದು ಅಡಿಯಲ್ಲಿ ನೂರಾರು ರೈತರು ಬರ್ತ ಇರ್ತಾರೆ ತಾವೇ ಬಂದು ಬೆಟ್ಟೆ ಹಾಕ್ತಾಯ ಇರ್ತಾರೆ'], [' ನಿರಂತರ ಇರ್ತದೆ ನನ್ನ ರೈತರ ಸಂಪರ್ಕ ಬೇರೆ ಬೇರೆ ಸಂಘ ಸಂಸ್ಥೆಗಳು ಬರ್ತಾ ಒಂದು ಅಡಿಯಲ್ಲಿ ನೂರಾರು ರೈತರು ಬರ್ತ ಇರ್ತಾರೆ ತಾವೇ ಬಂದು ಬೆಟ್ಟೆ ಹಾಕ್ತಾಯ ಇರ್ತಾರೆ']) ([' ಪ್ರತಿ ತಿಂಗಳು ಮೂರನೇ ಭಾನುವಾರ ನಮ್ಮಲ್ಲೊಂದು ಗ್ರೂಪ್ ಡಿಸ್ಕಶನ್ ಇರ್ತದೆ ಯಾವುದಾದ್ರೂ ರೈತರು ಕೃಷಿ ಅರಣ್ಯದ ಬಗ್ಗೆ ಗೊಂದಲಗಳಿರ್ತವೆ ಅದರ ಡೂಸ್ ಏನು ಡೋನ್ಸ್ ಏನು'], [' ಪ್ರತಿ ತಿಂಗಳು ಮೂರನೇ ಭಾನುವಾರ ನಮ್ಮಲ್ಲೊಂದು ಗ್ರೂಪ್ ಡಿಸ್ಕಶನ್ ಇರ್ತದೆ ಯಾವುದಾದ್ರೂ ರೈತರು ಕೃಷಿ ಅರಣ್ಯದ ಬಗ್ಗೆ ಗೊಂದಲಗಳಿರ್ತವೆ ಅದರ ಡೂಸ್ ಏನು ಡೋನ್ಸ್ ಏನು']) ([' ಅಂತ ಹಿಂಗಾಗಿ ಏನು ಮಾಡ್ತೀನಿ ಪ್ರತಿ ತಿಂಗಳು ಮೂರನೇ ಭಾನುವಾರ ಬೆಳಗ್ಗೆ ಒಂಬತ್ತು ಗಂಟೆಗೆ ನಮ್ಮಲ್ಲೊಂದು ಕೃಷಿ ಅರಣ್ಯ ಪದ್ಧತಿ ಮಾದರಿಗಳ ಬಗ್ಗೆ ಒಂದು ವಿಚಾರ'], [' ಅಂತ ಹಿಂಗಾಗಿ ಏನು ಮಾಡ್ತೀನಿ ಪ್ರತಿ ತಿಂಗಳು ಮೂರನೇ ಭಾನುವಾರ ಬೆಳಗ್ಗೆ ಒಂಬತ್ತು ಗಂಟೆಗೆ ನಮ್ಮಲ್ಲೊಂದು ಕೃಷಿ ಅರಣ್ಯ ಪದ್ಧತಿ ಮಾದರಿಗಳ ಬಗ್ಗೆ ಒಂದು ವಿಚಾರ'])\n",
            "Extracted Audio: /content/extracted_segments2/segment_SandalWoodNewsStories_9.mp3_650.00_690.00.mp3\n",
            "----------------------------------------\n",
            "\n",
            "Passage 2 (Relevance Score: 0.600):\n",
            "Audio File: SandalWoodNewsStories_176.mp3\n",
            "Time Range: 100.00s - 140.00s\n",
            "English Translation: ([ 'Our farmers today, what has happened to them is that they have been relying on just one crop or one side business, and farmers are incurring huge losses, so we'], [' 'Our farmers today, what has happened to them is that they have been relying on just one crop or one side business, and farmers are incurring huge losses, so we']) (One of the objectives of this concept is to carry out comprehensive agriculture without borewells. Here, comprehensive agriculture means that the specialty of our Green Wood Farm is that], [One of the objectives of this concept is to carry out comprehensive agriculture without borewells. Here, comprehensive agriculture means that the specialty of our Green Wood Farm is that]) ([‘There is no such agriculture Anna. We have taken into consideration every agricultural concept in our farm sir. It means sheep, hen, fish, indigenous cow, earthworm, forest’], [‘There is no such agriculture Anna. We have taken into consideration every agricultural concept in our farm sir. It means sheep, hen, fish, indigenous cow, earthworm, forest’])\n",
            "Original Kannada: ([' ನಮ್ಮ ರೈತರು ಇವತ್ತ ಏನಾಗ್ತಾಯಿದ್ದಾರೆ ಅಂತಂದರೆ ಯಾವುದೋ ಒಂದು ಬೆಳೆಯನ್ನು ಒಂದು ಉಪಕಸಬನ್ನು ಒಂದನ್ನು ನಂಬ್ಕೊಂಡು ಹೋಗ್ತಾಯ್ದಿದ್ದಾರೆ ರೈತರು ತುಂಬ ಲಾಸ್ ಆಗ್ತಾಯಿದ್ದಾರೆ ಅದಕ್ಕಾಗಿ ನಾವು ಈ ಒಂದು ಮೂರುವರೆ ಎಕರೆೆಯಲ್ಲಿ'], [' ನಮ್ಮ ರೈತರು ಇವತ್ತ ಏನಾಗ್ತಾಯಿದ್ದಾರೆ ಅಂತಂದರೆ ಯಾವುದೋ ಒಂದು ಬೆಳೆಯನ್ನು ಒಂದು ಉಪಕಸಬನ್ನು ಒಂದನ್ನು ನಂಬ್ಕೊಂಡು ಹೋಗ್ತಾಯ್ದಿದ್ದಾರೆ ರೈತರು ತುಂಬ ಲಾಸ್ ಆಗ್ತಾಯಿದ್ದಾರೆ ಅದಕ್ಕಾಗಿ ನಾವು ಈ ಒಂದು ಮೂರುವರೆ ಎಕರೆೆಯಲ್ಲಿ']) ([' ಬೋರ್ ವಲ್ ಇಲ್ಲದೇನೆೇ ಒಂದು ಸಮಗ್ರ ಕೃಷಿಯನ್ನ ಮಾಡಿರ್ತಕ್ಕಥದ್ದು ಈ ಒಂದು ಕಾನ್ಸೆಪ್್ಟತ ನ ಒಂದು ಉದ್ದೇಶ ಆಗಿದೆ ಇಲ್ಲಿ ಸಮಗ್ರ ಕೃಷಿ ಅಂತಂದ್ರೆ ನಮ್ಮ ಈ ಒಂದು ಗ್ರೀನ್ ವಡ್ ಫಾರ್ಮ್ ನ ವಿಶೇಷತೆ ಏನಾಗಿದೆ ಅಂದ್ರೆ'], [' ಬೋರ್ ವಲ್ ಇಲ್ಲದೇನೆೇ ಒಂದು ಸಮಗ್ರ ಕೃಷಿಯನ್ನ ಮಾಡಿರ್ತಕ್ಕಥದ್ದು ಈ ಒಂದು ಕಾನ್ಸೆಪ್್ಟತ ನ ಒಂದು ಉದ್ದೇಶ ಆಗಿದೆ ಇಲ್ಲಿ ಸಮಗ್ರ ಕೃಷಿ ಅಂತಂದ್ರೆ ನಮ್ಮ ಈ ಒಂದು ಗ್ರೀನ್ ವಡ್ ಫಾರ್ಮ್ ನ ವಿಶೇಷತೆ ಏನಾಗಿದೆ ಅಂದ್ರೆ']) ([' ಇಂತ ಒಂದು ಆಗ್ರಿಕಲ್ಚರ ಇಲ್ಲ ಅನ್ನಂಗಿಲ್ಲ ನಮ್ ಫಾರ್ಮಲ ಪ್ರತಿಯೊಂದು ಆಗ್ರಿಕಲ್ಚರ ಕಾನ್ಸೆಪ್ಟತ ಉ ಇಟ್ಕೊಂಡಿದ್ವಿ ಸಿರ್ ಇದ್ರಲ್ಲಿ ಏನಂತಂದ್ರೆ ಕುರಿ ಕೋಳಿ ಮೀನು ದೇಶ್ಯ ಹಾಕಳು ಎರೆಹುಳು ಅರಣ್ಯ ಪ'], [' ಇಂತ ಒಂದು ಆಗ್ರಿಕಲ್ಚರ ಇಲ್ಲ ಅನ್ನಂಗಿಲ್ಲ ನಮ್ ಫಾರ್ಮಲ ಪ್ರತಿಯೊಂದು ಆಗ್ರಿಕಲ್ಚರ ಕಾನ್ಸೆಪ್ಟತ ಉ ಇಟ್ಕೊಂಡಿದ್ವಿ ಸಿರ್ ಇದ್ರಲ್ಲಿ ಏನಂತಂದ್ರೆ ಕುರಿ ಕೋಳಿ ಮೀನು ದೇಶ್ಯ ಹಾಕಳು ಎರೆಹುಳು ಅರಣ್ಯ ಪ'])\n",
            "Extracted Audio: /content/extracted_segments2/segment_SandalWoodNewsStories_176.mp3_100.00_140.00.mp3\n",
            "----------------------------------------\n",
            "\n",
            "Passage 3 (Relevance Score: 0.500):\n",
            "Audio File: SandalWoodNewsStories_175.mp3\n",
            "Time Range: 170.00s - 210.00s\n",
            "English Translation: [' Commercial name Trade name Today I want to say on this one occasion especially to our youth'], [' Commercial name Trade name Today I want to say on this one occasion especially to our youth']) ['Farmers and young people who have lands and are interested in agriculture, the land amendment act of 2001 and 2002'], ['Farmers and young people who have lands and are interested in agriculture, the land amendment act of 2001 and 2002']) [‘I must say that this is a great opportunity for a private person to grow sandalwood because in 1792, Tipu Sultan had done one'], [‘I must say that this is a great opportunity for a private person to grow sandalwood because in 1792, Tipu Sultan had done one’]\n",
            "Original Kannada: ([' ಕಮರ್ಷಿಯಲ್ ನೇಮ್ ವಾಣಿಜ್ಯ ಹೆಸರು ಇವತ್ತು ನಾನು ಈ ಒಂದು ಸಂದರ್ಭದಲ್ಲಿ ಹೇಳಬೇಕೆಂದ್ರ ವಿಶೇಷವಾಗಿ ನಮ್ಮ ಯುವ ರ'], [' ಕಮರ್ಷಿಯಲ್ ನೇಮ್ ವಾಣಿಜ್ಯ ಹೆಸರು ಇವತ್ತು ನಾನು ಈ ಒಂದು ಸಂದರ್ಭದಲ್ಲಿ ಹೇಳಬೇಕೆಂದ್ರ ವಿಶೇಷವಾಗಿ ನಮ್ಮ ಯುವ ರ']) ([' ರೈತರು ಯುವಕರು ಏನು ಭೂಮಿ ಇಟ್ಕೊಂಡಿದ್ದಾರೆ ಕೃಷಿ ಬಗ್ಗೆ ಆಸಕ್ತಿ ಇದೆ ಇವತ್ತೇನು ಎರಡು ಸಾವಿರದ ಒಂದು ಎರಡರಲ್ಲಿ ೇನು ಲಾ ಅಮೆಂಡ್ಮೆಂಟ್ ಆಗಿದೆ'], [' ರೈತರು ಯುವಕರು ಏನು ಭೂಮಿ ಇಟ್ಕೊಂಡಿದ್ದಾರೆ ಕೃಷಿ ಬಗ್ಗೆ ಆಸಕ್ತಿ ಇದೆ ಇವತ್ತೇನು ಎರಡು ಸಾವಿರದ ಒಂದು ಎರಡರಲ್ಲಿ ೇನು ಲಾ ಅಮೆಂಡ್ಮೆಂಟ್ ಆಗಿದೆ']) ([' ಪ್ರೈವೇಟ್ ಪರ್ಸನ್ ಕ್ಯಾನ್ ಗ್ರೋ ಸ್ಯಾಂಡಲ್ ಅಂತ ಇದೊಂದು ದೊಡ್ಡ ಅವಕಾಶ ಅಂತ ನಾನು ಹೇಳ್ಬೋದು ಈ ಸಂದರ್ಭದಲ್ಲಿ ಯಾಕಂತಂದರೆ ಹದಿನೇಳುನೂರ ಎಂಬತ್ತೆರಡರಲ್ಲಿ ಟಿಪ್ಪು ಸುಲ್ತಾನ್ ಮಾಡಿದ್ದ ಒಂದು'], [' ಪ್ರೈವೇಟ್ ಪರ್ಸನ್ ಕ್ಯಾನ್ ಗ್ರೋ ಸ್ಯಾಂಡಲ್ ಅಂತ ಇದೊಂದು ದೊಡ್ಡ ಅವಕಾಶ ಅಂತ ನಾನು ಹೇಳ್ಬೋದು ಈ ಸಂದರ್ಭದಲ್ಲಿ ಯಾಕಂತಂದರೆ ಹದಿನೇಳುನೂರ ಎಂಬತ್ತೆರಡರಲ್ಲಿ ಟಿಪ್ಪು ಸುಲ್ತಾನ್ ಮಾಡಿದ್ದ ಒಂದು'])\n",
            "Extracted Audio: /content/extracted_segments2/segment_SandalWoodNewsStories_175.mp3_170.00_210.00.mp3\n",
            "----------------------------------------\n",
            "\n",
            "Passage 4 (Relevance Score: 0.500):\n",
            "Audio File: SandalWoodNewsStories_174.mp3\n",
            "Time Range: 580.00s - 620.00s\n",
            "English Translation: [A farmer is not one who has a forehead indicating he would be a rider, sir, he must toil in the sun, get drenched in the rain and walk in the cold, only then will there be one or two bags of grain in his house], [A farmer is not one who has a forehead indicating he would be a rider, sir, he must toil in the sun, get drenched in the rain and walk in the cold, only then will there be one or two bags of grain in his house] ([' If he gets the rate, he will give two hundred rupees in his hand, if he doesn't get the rate then he will stand in front of the fertilizer shop and talk with bloodshot eyes, because he has made debts'], [' If he gets the rate, he will give two hundred rupees in his hand, if he doesn't get the rate then he will stand in front of the fertilizer shop and talk with bloodshot eyes, because he has made debts']) ([' Do, sir, this year keep the principal and next year I will pay the interest. He requested with folded hands, standing in front of you today. He says that if I speak, I will not see the day'], [' Do, sir, this year keep the principal and next year I will pay the interest. He requested with folded hands, standing in front of you today. He says that if I speak, I will not see the day'])\n",
            "Original Kannada: ([' ಸವಾರ ತಗೊಳ್ಳುವಂತ ಹಣೆ ಬರ ರೈತಂದ ಇರುವುದಿಲ್ಲ ಸಿರ ಅವನ ಬಿಸಲಲ್ಲಿ ಸೊಡಬೇಕಾಗ್ತದ ಮಳಿಯೊಳಗ ನೆನಿಬೇಕಾಗ್ತದ ಥಂಡಿಯೊಳಗ ನಡಗಬೇಕಾಗ್ತದ ಅವಾಗಷ್ಟ ಅವನ ಮನಿಯೊಳಗ ಒಂದ ಎರಡು ಚೀಲಾ ಕಾಳಿ ಇರ್ತಾವ'], [' ಸವಾರ ತಗೊಳ್ಳುವಂತ ಹಣೆ ಬರ ರೈತಂದ ಇರುವುದಿಲ್ಲ ಸಿರ ಅವನ ಬಿಸಲಲ್ಲಿ ಸೊಡಬೇಕಾಗ್ತದ ಮಳಿಯೊಳಗ ನೆನಿಬೇಕಾಗ್ತದ ಥಂಡಿಯೊಳಗ ನಡಗಬೇಕಾಗ್ತದ ಅವಾಗಷ್ಟ ಅವನ ಮನಿಯೊಳಗ ಒಂದ ಎರಡು ಚೀಲಾ ಕಾಳಿ ಇರ್ತಾವ']) ([' ರೇಟೆ ಸಿಕ್ಕ್ರೆ ಎಂತಿಿಕೈೊಳಗ್ ಎರಡ್ ಸಾವ್ರ ರೂಪಾಯ ಕೊಡ್ತಾನ ರೇಟೆ ಸಿಗ್ಲಿಲ್ಲ ಅಂದ್ರೆ ಗೊಬ್ಬರದ ಅಂಗಡಿ ಅವ್ನ್ ಮುಂದ್ ಹೋಗಿ ಕಣ್ಣಳಗ್ ಕಣ್ಣಿಟ್ ಮಾತಾಡ್ಲಿಕ್ಕ ಆಗಲ್ಲ ಸಿರ ಯಾಕಂದ್ರೆ ಸಾಲ ಮಾಡಿರ್ತಾನಲಿ ಕೆಳಗ್'], [' ರೇಟೆ ಸಿಕ್ಕ್ರೆ ಎಂತಿಿಕೈೊಳಗ್ ಎರಡ್ ಸಾವ್ರ ರೂಪಾಯ ಕೊಡ್ತಾನ ರೇಟೆ ಸಿಗ್ಲಿಲ್ಲ ಅಂದ್ರೆ ಗೊಬ್ಬರದ ಅಂಗಡಿ ಅವ್ನ್ ಮುಂದ್ ಹೋಗಿ ಕಣ್ಣಳಗ್ ಕಣ್ಣಿಟ್ ಮಾತಾಡ್ಲಿಕ್ಕ ಆಗಲ್ಲ ಸಿರ ಯಾಕಂದ್ರೆ ಸಾಲ ಮಾಡಿರ್ತಾನಲಿ ಕೆಳಗ್']) ([' ಮಾಡಿ ಯಪ್ಪಾ ಈ ವರ್ಷ ಅಸಲ ಇಟ್ಕೊಂಡ ಮುಂದಿನ ವರ್ಷ ಬಡ್ಡಿ ಕೊಡ್ತೀನಿ ಅಂತ ರೇಕೆಸ್ಟ್ ಮಾಡಿ ಕೈ ಮುಗಿದು ಬಂದಿರ್ತಾನೆ ಇವತ್ ನಿಮ್ಮ ಮುಂದ ನಿಿಂತ ನ ಮಾತಾಡ್ಲಿಕ್ಕತ್ತನ ಅಂದ್ರೆ ನಾ ದಿನಾ ನೋಡಿಲ್ಲ ಅಂತ ತಿಳ್ಕೊಂಡ'], [' ಮಾಡಿ ಯಪ್ಪಾ ಈ ವರ್ಷ ಅಸಲ ಇಟ್ಕೊಂಡ ಮುಂದಿನ ವರ್ಷ ಬಡ್ಡಿ ಕೊಡ್ತೀನಿ ಅಂತ ರೇಕೆಸ್ಟ್ ಮಾಡಿ ಕೈ ಮುಗಿದು ಬಂದಿರ್ತಾನೆ ಇವತ್ ನಿಮ್ಮ ಮುಂದ ನಿಿಂತ ನ ಮಾತಾಡ್ಲಿಕ್ಕತ್ತನ ಅಂದ್ರೆ ನಾ ದಿನಾ ನೋಡಿಲ್ಲ ಅಂತ ತಿಳ್ಕೊಂಡ'])\n",
            "Extracted Audio: /content/extracted_segments2/segment_SandalWoodNewsStories_174.mp3_580.00_620.00.mp3\n",
            "----------------------------------------\n",
            "\n",
            "Passage 5 (Relevance Score: 0.491):\n",
            "Audio File: SandalWoodNewsStories_156.mp3\n",
            "Time Range: 290.00s - 330.00s\n",
            "English Translation: ([Farmers are tilling the soil and doing all the ploughing and sowing in the agricultural land.], [Farmers are tilling the soil and doing all the ploughing and sowing in the agricultural land.]) (In the beginning, we put one manure of cow dung per each plant in the yard of Ratan Farm in the village of Doddhapalya), (Fertilizer in the beginning, manure of cow dung of Ratan Farm, yard of Doddhapalya, we put one manure per each plant) ([' It doesn't grow as good as it should. It grows poorly and the host plant with which it lives is important'], [' It doesn't grow as good as it should. It grows poorly and the host plant with which it lives is important'])\n",
            "Original Kannada: ([' ಫಾರ್ಮರ್ಸ್ ಆಗ್ರಿಕಲ್ಚರ ಲಂಡ್ ಅಲ್ಲಿ ಫೂಲ ಉಳುಮೆ ಮಾಡ್ಕೊಂಡು ಪ್ಲೋಇಂಗ್ ಎಲ್ಲ ಮಾಡಿ ನೆಟ್ಬೋದು ಆ'], [' ಫಾರ್ಮರ್ಸ್ ಆಗ್ರಿಕಲ್ಚರ ಲಂಡ್ ಅಲ್ಲಿ ಫೂಲ ಉಳುಮೆ ಮಾಡ್ಕೊಂಡು ಪ್ಲೋಇಂಗ್ ಎಲ್ಲ ಮಾಡಿ ನೆಟ್ಬೋದು ಆ']) ([' ಇನೀತಿಯಲ್ಲಿ ಗೊಬ್ಬರ ದನದ ವೆಲ್ ರಾಟನ್ ಫಾರ್ಮ ಯಾರ್ಡ್ ಮನ ದದೊ ಹ ಪ್ರತಿಯೊಂದು ಗಿಡಕ್ಕೆ ನಾವ ಒಂದು ಎರ ಬಿಡ್ತೀ'], [' ಇನೀತಿಯಲ್ಲಿ ಗೊಬ್ಬರ ದನದ ವೆಲ್ ರಾಟನ್ ಫಾರ್ಮ ಯಾರ್ಡ್ ಮನ ದದೊ ಹ ಪ್ರತಿಯೊಂದು ಗಿಡಕ್ಕೆ ನಾವ ಒಂದು ಎರ ಬಿಡ್ತೀ']) ([' ರಷ್ಟು ಹ ಹ ಉತ್ಕೃಷ್ಟವಾಗಿ ಬೆಳುತ್ತೆ ಅಂತೇಳಿತ್ೃಷ್ಟವಾಗಿ ಬೆಳತದೆ ಅದರ ಜೊತೆ ಹೋಸ್ಟ್ ಪ್ಲಾಂಟ್ ಹ ಹ ಹ ಅದು ಬಾಳ ಮುಖ್ಯ ಹ'], [' ರಷ್ಟು ಹ ಹ ಉತ್ಕೃಷ್ಟವಾಗಿ ಬೆಳುತ್ತೆ ಅಂತೇಳಿತ್ೃಷ್ಟವಾಗಿ ಬೆಳತದೆ ಅದರ ಜೊತೆ ಹೋಸ್ಟ್ ಪ್ಲಾಂಟ್ ಹ ಹ ಹ ಅದು ಬಾಳ ಮುಖ್ಯ ಹ'])\n",
            "Extracted Audio: /content/extracted_segments2/segment_SandalWoodNewsStories_156.mp3_290.00_330.00.mp3\n",
            "----------------------------------------\n",
            "\n",
            "Entering interactive mode...\n",
            "\n",
            "Enter your question (or 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import gc\n",
        "import os\n",
        "from typing import Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "def setup_model(model_path: str) -> nemo_asr.models.EncDecCTCModel:\n",
        "    \"\"\"Initialize the ASR model.\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = nemo_asr.models.EncDecCTCModel.restore_from(restore_path=model_path)\n",
        "    model.freeze()\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "def process_audio(audio_path: str) -> Tuple[torch.Tensor, int]:\n",
        "    \"\"\"Load and preprocess audio file.\"\"\"\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "    resampled_waveform = resampler(waveform)\n",
        "\n",
        "    # Convert stereo to mono if necessary\n",
        "    if resampled_waveform.size(0) > 1:\n",
        "        resampled_waveform = resampled_waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    return resampled_waveform.squeeze(0), 16000\n",
        "\n",
        "def transcribe_single_audio(model: nemo_asr.models.EncDecCTCModel, audio_path: str) -> str:\n",
        "    \"\"\"Transcribe a single audio file and return the transcription.\"\"\"\n",
        "    try:\n",
        "        # Process audio\n",
        "        input_signal, _ = process_audio(audio_path)\n",
        "        input_signal = input_signal.to(model.device)\n",
        "\n",
        "        # Get transcription\n",
        "        transcript = model.transcribe(\n",
        "            input_signal,\n",
        "            batch_size=1,\n",
        "            logprobs=False,\n",
        "            language_id='kn'\n",
        "        )[0]\n",
        "\n",
        "        # Clean up\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        del input_signal\n",
        "        gc.collect()\n",
        "\n",
        "        return transcript\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error processing audio: {str(e)}\"\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    model_path = '/content/ai4b_indicConformer_kn.nemo'  # Update with your model path\n",
        "\n",
        "    print(\"Welcome to the Kannada Audio Transcription System!\")\n",
        "\n",
        "    # Initialize model\n",
        "    try:\n",
        "        print(\"\\nLoading the transcription model...\")\n",
        "        model = setup_model(model_path)\n",
        "        print(\"Model loaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        # Get audio file path from user\n",
        "        print(\"\\nEnter the path to your audio file (or 'quit' to exit):\")\n",
        "        audio_path = input().strip()\n",
        "\n",
        "        if audio_path.lower() == 'quit':\n",
        "            print(\"Thank you for using the transcription system. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Verify file exists\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(\"Error: File does not exist. Please check the path and try again.\")\n",
        "            continue\n",
        "\n",
        "        # Verify file is an audio file\n",
        "        if not audio_path.lower().endswith(('.mp3', '.wav', '.flac', '.ogg')):\n",
        "            print(\"Error: File must be an audio file (mp3, wav, flac, or ogg)\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nTranscribing {os.path.basename(audio_path)}...\")\n",
        "        transcript = transcribe_single_audio(model, audio_path)\n",
        "\n",
        "        print(\"\\nTranscription Result:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(transcript)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Clean up\n",
        "    del model\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "KB1wqu2J99G8",
        "outputId": "f6ab3fc2-3354-4c73-b65b-023d08035f36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Kannada Audio Transcription System!\n",
            "\n",
            "Loading the transcription model...\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:198] _setup_tokenizer: detected an aggregate tokenizer\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:40:02 multilingual_tokenizer:61] Aggregate vocab size: 5632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-17 16:40:10 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/train/train_kannada.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    max_duration: 30.0\n",
            "    min_duration: 0.2\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    shuffle_n: 2048\n",
            "    bucketing_strategy: synced_randomized\n",
            "    bucketing_batch_size: null\n",
            "    is_concat: true\n",
            "    concat_sampling_technique: temperature\n",
            "    concat_sampling_temperature: 1.5\n",
            "    return_language_id: true\n",
            "    \n",
            "[NeMo W 2024-11-17 16:40:10 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/valid_datasetwise/valid_kannada_indicvoices.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    return_language_id: true\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-17 16:40:10 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-17 16:40:10 features:289] PADDING: 0\n",
            "[NeMo I 2024-11-17 16:40:13 rnnt:1663] Vocab size for each language: 256\n",
            "[NeMo I 2024-11-17 16:40:13 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:40:13 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:40:16 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:40:16 hybrid_rnnt_ctc_bpe_models:105] Creating masks for multi-softmax layer.\n",
            "[NeMo I 2024-11-17 16:40:16 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:40:17 save_restore_connector:263] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /content/ai4b_indicConformer_kn.nemo.\n",
            "Model loaded successfully!\n",
            "\n",
            "Enter the path to your audio file (or 'quit' to exit):\n",
            "/content/Test.mp3\n",
            "\n",
            "Transcribing Test.mp3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transcription Result:\n",
            "--------------------------------------------------\n",
            "[' ರೈತರ ಬಗ್ಗೆ ಏನು ಪ್ರಸ್ತಾಪಿಸಲಾಗಿದೆ']\n",
            "--------------------------------------------------\n",
            "\n",
            "Enter the path to your audio file (or 'quit' to exit):\n",
            "quit\n",
            "Thank you for using the transcription system. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import gc\n",
        "import os\n",
        "from typing import Tuple\n",
        "from pathlib import Path\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "def setup_model(model_path: str) -> nemo_asr.models.EncDecCTCModel:\n",
        "    \"\"\"Initialize the ASR model.\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = nemo_asr.models.EncDecCTCModel.restore_from(restore_path=model_path)\n",
        "    model.freeze()\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "def process_audio(audio_path: str) -> Tuple[torch.Tensor, int]:\n",
        "    \"\"\"Load and preprocess audio file.\"\"\"\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "    resampled_waveform = resampler(waveform)\n",
        "\n",
        "    # Convert stereo to mono if necessary\n",
        "    if resampled_waveform.size(0) > 1:\n",
        "        resampled_waveform = resampled_waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    return resampled_waveform.squeeze(0), 16000\n",
        "\n",
        "def translate_text(text: str, llm: ChatGoogleGenerativeAI) -> str:\n",
        "    \"\"\"Translate Kannada text to English using Gemini.\"\"\"\n",
        "    prompt = f\"Translate this Kannada text to English: {text}\"\n",
        "    try:\n",
        "        response = llm.invoke(prompt)\n",
        "        return str(response.content)\n",
        "    except Exception as e:\n",
        "        return f\"Translation error: {str(e)}\"\n",
        "\n",
        "def transcribe_and_translate_audio(model: nemo_asr.models.EncDecCTCModel,\n",
        "                                 llm: ChatGoogleGenerativeAI,\n",
        "                                 audio_path: str) -> tuple:\n",
        "    \"\"\"Transcribe audio and translate the transcription.\"\"\"\n",
        "    try:\n",
        "        # Process audio\n",
        "        input_signal, _ = process_audio(audio_path)\n",
        "        input_signal = input_signal.to(model.device)\n",
        "\n",
        "        # Get transcription\n",
        "        transcript = model.transcribe(\n",
        "            input_signal,\n",
        "            batch_size=1,\n",
        "            logprobs=False,\n",
        "            language_id='kn'\n",
        "        )[0]\n",
        "\n",
        "        # Get translation\n",
        "        translation = translate_text(transcript, llm)\n",
        "\n",
        "        # Clean up\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        del input_signal\n",
        "        gc.collect()\n",
        "\n",
        "        return transcript, translation\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error processing audio: {str(e)}\", \"Translation not available due to error\"\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    model_path = '/content/ai4b_indicConformer_kn.nemo'  # Update with your model path\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC29gObkycJDBjVkEWjhJoJO-HVB0pC00E\"  # Replace with your key\n",
        "\n",
        "    print(\"Welcome to the Kannada Audio Transcription and Translation System!\")\n",
        "\n",
        "    # Initialize models\n",
        "    try:\n",
        "        print(\"\\nLoading the transcription model...\")\n",
        "        asr_model = setup_model(model_path)\n",
        "        print(\"ASR Model loaded successfully!\")\n",
        "\n",
        "        print(\"\\nInitializing translation model...\")\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "        print(\"Translation model initialized!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading models: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        # Get audio file path from user\n",
        "        print(\"\\nEnter the path to your audio file (or 'quit' to exit):\")\n",
        "        audio_path = input().strip()\n",
        "\n",
        "        if audio_path.lower() == 'quit':\n",
        "            print(\"Thank you for using the system. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Verify file exists\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(\"Error: File does not exist. Please check the path and try again.\")\n",
        "            continue\n",
        "\n",
        "        # Verify file is an audio file\n",
        "        if not audio_path.lower().endswith(('.mp3', '.wav', '.flac', '.ogg')):\n",
        "            print(\"Error: File must be an audio file (mp3, wav, flac, or ogg)\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcessing {os.path.basename(audio_path)}...\")\n",
        "        transcript, translation = transcribe_and_translate_audio(asr_model, llm, audio_path)\n",
        "\n",
        "        print(\"\\nResults:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(\"Original Kannada Transcription:\")\n",
        "        print(transcript)\n",
        "        print(\"\\nEnglish Translation:\")\n",
        "        print(translation)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Clean up\n",
        "    del asr_model\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "rIAuHRwMBC4B",
        "outputId": "f094641e-013a-4107-8cd7-54363bd808d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Kannada Audio Transcription and Translation System!\n",
            "\n",
            "Loading the transcription model...\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:198] _setup_tokenizer: detected an aggregate tokenizer\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:46:19 multilingual_tokenizer:61] Aggregate vocab size: 5632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-17 16:46:29 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/train/train_kannada.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    max_duration: 30.0\n",
            "    min_duration: 0.2\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    shuffle_n: 2048\n",
            "    bucketing_strategy: synced_randomized\n",
            "    bucketing_batch_size: null\n",
            "    is_concat: true\n",
            "    concat_sampling_technique: temperature\n",
            "    concat_sampling_temperature: 1.5\n",
            "    return_language_id: true\n",
            "    \n",
            "[NeMo W 2024-11-17 16:46:29 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/valid_datasetwise/valid_kannada_indicvoices.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    return_language_id: true\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-17 16:46:29 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-17 16:46:29 features:289] PADDING: 0\n",
            "[NeMo I 2024-11-17 16:46:31 rnnt:1663] Vocab size for each language: 256\n",
            "[NeMo I 2024-11-17 16:46:32 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:46:32 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:46:34 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:46:34 hybrid_rnnt_ctc_bpe_models:105] Creating masks for multi-softmax layer.\n",
            "[NeMo I 2024-11-17 16:46:34 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:46:35 save_restore_connector:263] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /content/ai4b_indicConformer_kn.nemo.\n",
            "ASR Model loaded successfully!\n",
            "\n",
            "Initializing translation model...\n",
            "Translation model initialized!\n",
            "\n",
            "Enter the path to your audio file (or 'quit' to exit):\n",
            "/content/Test.mp3\n",
            "\n",
            "Processing Test.mp3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 21.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "--------------------------------------------------\n",
            "Original Kannada Transcription:\n",
            "[' ರೈತರ ಬಗ್ಗೆ ಏನು ಪ್ರಸ್ತಾಪಿಸಲಾಗಿದೆ']\n",
            "\n",
            "English Translation:\n",
            "['What is proposed about farmers']\n",
            "--------------------------------------------------\n",
            "\n",
            "Enter the path to your audio file (or 'quit' to exit):\n",
            "quit\n",
            "Thank you for using the system. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import gc\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "from pathlib import Path\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import pandas as pd\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from pydub import AudioSegment\n",
        "import ast\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CombinedAudioSystem:\n",
        "    def __init__(self, model_path: str, csv_path: str, audio_dir: str, output_dir: str = \"./extracted_segments\"):\n",
        "        \"\"\"Initialize both ASR and RAG systems\"\"\"\n",
        "        # Initialize ASR model\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.asr_model = self.setup_model(model_path)\n",
        "\n",
        "        # Initialize Gemini\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC29gObkycJDBjVkEWjhJoJO-HVB0pC00E\"\n",
        "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "\n",
        "        # Initialize RAG system\n",
        "        self.csv_path = csv_path\n",
        "        self.audio_dir = audio_dir\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Load existing data and initialize RAG\n",
        "        self.df = self.load_and_prepare_data()\n",
        "        self.documents = self.create_documents()\n",
        "        self.vector_store = self.initialize_vector_store()\n",
        "        self.audio_cache = {}\n",
        "\n",
        "    def setup_model(self, model_path: str) -> nemo_asr.models.EncDecCTCModel:\n",
        "        \"\"\"Initialize the ASR model.\"\"\"\n",
        "        model = nemo_asr.models.EncDecCTCModel.restore_from(restore_path=model_path)\n",
        "        model.freeze()\n",
        "        model = model.to(self.device)\n",
        "        return model\n",
        "\n",
        "    def process_audio(self, audio_path: str) -> Tuple[torch.Tensor, int]:\n",
        "        \"\"\"Load and preprocess audio file.\"\"\"\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "        resampled_waveform = resampler(waveform)\n",
        "\n",
        "        if resampled_waveform.size(0) > 1:\n",
        "            resampled_waveform = resampled_waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        return resampled_waveform.squeeze(0), 16000\n",
        "\n",
        "    def translate_text(self, text: str) -> str:\n",
        "        \"\"\"Translate Kannada text to English using Gemini.\"\"\"\n",
        "        prompt = f\"Translate this Kannada text to English: {text}\"\n",
        "        try:\n",
        "            response = self.llm.invoke(prompt)\n",
        "            return str(response.content)\n",
        "        except Exception as e:\n",
        "            return f\"Translation error: {str(e)}\"\n",
        "\n",
        "    def transcribe_and_translate_audio(self, audio_path: str) -> tuple:\n",
        "        \"\"\"Transcribe audio and translate the transcription.\"\"\"\n",
        "        try:\n",
        "            input_signal, _ = self.process_audio(audio_path)\n",
        "            input_signal = input_signal.to(self.device)\n",
        "\n",
        "            transcript = self.asr_model.transcribe(\n",
        "                input_signal,\n",
        "                batch_size=1,\n",
        "                logprobs=False,\n",
        "                language_id='kn'\n",
        "            )[0]\n",
        "\n",
        "            translation = self.translate_text(transcript)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            del input_signal\n",
        "            gc.collect()\n",
        "\n",
        "            return transcript, translation\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing audio: {str(e)}\", \"Translation not available due to error\"\n",
        "\n",
        "    def load_and_prepare_data(self) -> pd.DataFrame:\n",
        "        \"\"\"Load and prepare the CSV data.\"\"\"\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "        df['time_aligned_transcripts'] = df['time_aligned_transcripts'].apply(\n",
        "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        "        )\n",
        "        df['time_aligned_translations'] = df['time_aligned_translations'].apply(\n",
        "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        "        )\n",
        "        return df\n",
        "\n",
        "    def create_documents(self) -> List[Document]:\n",
        "        \"\"\"Create documents for vector store.\"\"\"\n",
        "        documents = []\n",
        "        for idx, row in self.df.iterrows():\n",
        "            for time_range, translation in row['time_aligned_translations'].items():\n",
        "                metadata = {\n",
        "                    'audio_file': row['audio_file'],\n",
        "                    'time_range': time_range,\n",
        "                    'original_text': row['time_aligned_transcripts'].get(time_range, ''),\n",
        "                    'full_translation': row['full_transcript_translation']\n",
        "                }\n",
        "                doc = Document(\n",
        "                    page_content=translation,\n",
        "                    metadata=metadata\n",
        "                )\n",
        "                documents.append(doc)\n",
        "        return documents\n",
        "\n",
        "    def initialize_vector_store(self) -> FAISS:\n",
        "        \"\"\"Initialize the FAISS vector store.\"\"\"\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "        )\n",
        "        return FAISS.from_documents(self.documents, embeddings)\n",
        "\n",
        "    def calculate_relevance_score(self, question: str, doc: Document) -> float:\n",
        "        \"\"\"Calculate relevance score for document.\"\"\"\n",
        "        try:\n",
        "            embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "            )\n",
        "            question_emb = embeddings.embed_query(question)\n",
        "            doc_emb = embeddings.embed_query(doc.page_content)\n",
        "\n",
        "            semantic_score = F.cosine_similarity(\n",
        "                torch.tensor(question_emb).unsqueeze(0),\n",
        "                torch.tensor(doc_emb).unsqueeze(0)\n",
        "            ).item()\n",
        "\n",
        "            return semantic_score\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating relevance score: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def answer_question(self, question: str, k: int = 3) -> List[Dict]:\n",
        "        \"\"\"Search for relevant passages and return results.\"\"\"\n",
        "        docs = self.vector_store.similarity_search(question, k=k)\n",
        "        results = []\n",
        "\n",
        "        for doc in docs:\n",
        "            score = self.calculate_relevance_score(question, doc)\n",
        "            result = {\n",
        "                'relevance_score': score,\n",
        "                'audio_file': doc.metadata['audio_file'],\n",
        "                'time_range': doc.metadata['time_range'],\n",
        "                'english_translation': doc.page_content,\n",
        "                'original_kannada': doc.metadata['original_text']\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def print_results(self, results: List[Dict]):\n",
        "        \"\"\"Print results in a formatted way.\"\"\"\n",
        "        if not results:\n",
        "            print(\"\\nNo relevant passages found.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\nRelevant passages found (ranked by relevance):\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            print(f\"\\nPassage {i} (Relevance Score: {result['relevance_score']:.3f}):\")\n",
        "            print(f\"Audio File: {result['audio_file']}\")\n",
        "            print(f\"Time Range: {result['time_range']}\")\n",
        "            print(f\"English Translation: {result['english_translation']}\")\n",
        "            print(f\"Original Kannada: {result['original_kannada']}\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    model_path = '/content/ai4b_indicConformer_kn.nemo'\n",
        "    csv_path = \"/content/allfilescombined.csv\"\n",
        "    audio_dir = \"/content/audio-kannada\"\n",
        "    output_dir = \"/content/extracted_segments3\"\n",
        "\n",
        "    print(\"Welcome to the Combined Audio Processing System!\")\n",
        "\n",
        "    try:\n",
        "        print(\"\\nInitializing system...\")\n",
        "        system = CombinedAudioSystem(model_path, csv_path, audio_dir, output_dir)\n",
        "        print(\"System initialized successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing system: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nChoose an option:\")\n",
        "        print(\"1. Transcribe and translate new audio\")\n",
        "        print(\"2. Search existing transcriptions\")\n",
        "        print(\"3. Quit\")\n",
        "\n",
        "        choice = input(\"\\nEnter your choice (1-3): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            print(\"\\nEnter the path to your audio file:\")\n",
        "            audio_path = input().strip()\n",
        "\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(\"Error: File does not exist.\")\n",
        "                continue\n",
        "\n",
        "            if not audio_path.lower().endswith(('.mp3', '.wav', '.flac', '.ogg')):\n",
        "                print(\"Error: File must be an audio file (mp3, wav, flac, or ogg)\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nProcessing {os.path.basename(audio_path)}...\")\n",
        "            transcript, translation = system.transcribe_and_translate_audio(audio_path)\n",
        "\n",
        "            print(\"\\nResults:\")\n",
        "            print(\"-\" * 50)\n",
        "            print(\"Original Kannada Transcription:\")\n",
        "            print(transcript)\n",
        "            print(\"\\nEnglish Translation:\")\n",
        "            print(translation)\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            question = input(\"\\nEnter your search query: \")\n",
        "            results = system.answer_question(question)\n",
        "            system.print_results(results)\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            print(\"Thank you for using the system. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "tZFHK9aPCFOx",
        "outputId": "863e5ab3-d114-4439-bc00-20719c989931",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Combined Audio Processing System!\n",
            "\n",
            "Initializing system...\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:198] _setup_tokenizer: detected an aggregate tokenizer\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 16:50:50 multilingual_tokenizer:61] Aggregate vocab size: 5632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-17 16:51:01 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/train/train_kannada.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    max_duration: 30.0\n",
            "    min_duration: 0.2\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    shuffle_n: 2048\n",
            "    bucketing_strategy: synced_randomized\n",
            "    bucketing_batch_size: null\n",
            "    is_concat: true\n",
            "    concat_sampling_technique: temperature\n",
            "    concat_sampling_temperature: 1.5\n",
            "    return_language_id: true\n",
            "    \n",
            "[NeMo W 2024-11-17 16:51:01 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/valid_datasetwise/valid_kannada_indicvoices.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    return_language_id: true\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-17 16:51:01 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-17 16:51:01 features:289] PADDING: 0\n",
            "[NeMo I 2024-11-17 16:51:03 rnnt:1663] Vocab size for each language: 256\n",
            "[NeMo I 2024-11-17 16:51:03 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:51:03 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:51:05 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:51:05 hybrid_rnnt_ctc_bpe_models:105] Creating masks for multi-softmax layer.\n",
            "[NeMo I 2024-11-17 16:51:05 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 16:51:05 save_restore_connector:263] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /content/ai4b_indicConformer_kn.nemo.\n",
            "System initialized successfully!\n",
            "\n",
            "Choose an option:\n",
            "1. Transcribe and translate new audio\n",
            "2. Search existing transcriptions\n",
            "3. Quit\n",
            "\n",
            "Enter your choice (1-3): 1\n",
            "\n",
            "Enter the path to your audio file:\n",
            "/content/Test.mp3\n",
            "\n",
            "Processing Test.mp3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 22.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "--------------------------------------------------\n",
            "Original Kannada Transcription:\n",
            "[' ರೈತರ ಬಗ್ಗೆ ಏನು ಪ್ರಸ್ತಾಪಿಸಲಾಗಿದೆ']\n",
            "\n",
            "English Translation:\n",
            "[' What is proposed about farmers']\n",
            "--------------------------------------------------\n",
            "\n",
            "Choose an option:\n",
            "1. Transcribe and translate new audio\n",
            "2. Search existing transcriptions\n",
            "3. Quit\n",
            "\n",
            "Enter your choice (1-3): 2\n",
            "\n",
            "Enter your search query: what is proposed about farmers\n",
            "\n",
            "Relevant passages found (ranked by relevance):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Passage 1 (Relevance Score: 0.690):\n",
            "Audio File: SandalWoodNewsStories_174.mp3\n",
            "Time Range: 570.00s - 580.00s\n",
            "English Translation: [' The cropping system should provide income to the farmer in every season. Also, after forty-five to fifty years, it is not possible to work on the farm because by then, one can earn one lakh rupees by sitting in the room'], [' The cropping system should provide income to the farmer in every season. Also, after forty-five to fifty years, it is not possible to work on the farm because by then, one can earn one lakh rupees by sitting in the room']\n",
            "Original Kannada: ([' ಬೆಳೆ ಪದ್ಧತಿ ಪ್ರತಿಯೊಂದು ಋತುವಿನಿಂದ ರೈತನಿಗೆ ಆದಾಯ ಬರ್ತಿರಬೇಕು ಇನ್ನು ನಲವತ್ತೈದರಿಂದ ಐವತ್ತು ವರ್ಷ ಆದ ಮೇಲೆ ಹೊಲ ಮನಿಯೊಳಗ ದುಡಿಲಿಕ್ಕಾಗುವುದಿಲ್ಲ ಯಾಕಂದ್ರೆ ಆಕಿ ರೂಮ ಒಳಗ ಕುತ್ಕೊಂಡು ಒಂದು ಲಕ್ಷ ರೂಪಾಯಿ'], [' ಬೆಳೆ ಪದ್ಧತಿ ಪ್ರತಿಯೊಂದು ಋತುವಿನಿಂದ ರೈತನಿಗೆ ಆದಾಯ ಬರ್ತಿರಬೇಕು ಇನ್ನು ನಲವತ್ತೈದರಿಂದ ಐವತ್ತು ವರ್ಷ ಆದ ಮೇಲೆ ಹೊಲ ಮನಿಯೊಳಗ ದುಡಿಲಿಕ್ಕಾಗುವುದಿಲ್ಲ ಯಾಕಂದ್ರೆ ಆಕಿ ರೂಮ ಒಳಗ ಕುತ್ಕೊಂಡು ಒಂದು ಲಕ್ಷ ರೂಪಾಯಿ'])\n",
            "----------------------------------------\n",
            "\n",
            "Passage 2 (Relevance Score: 0.705):\n",
            "Audio File: SandalWoodNewsStories_175.mp3\n",
            "Time Range: 180.00s - 190.00s\n",
            "English Translation: ['Farmers and young people who have lands and are interested in agriculture, the land amendment act of 2001 and 2002'], ['Farmers and young people who have lands and are interested in agriculture, the land amendment act of 2001 and 2002'])\n",
            "Original Kannada: ([' ರೈತರು ಯುವಕರು ಏನು ಭೂಮಿ ಇಟ್ಕೊಂಡಿದ್ದಾರೆ ಕೃಷಿ ಬಗ್ಗೆ ಆಸಕ್ತಿ ಇದೆ ಇವತ್ತೇನು ಎರಡು ಸಾವಿರದ ಒಂದು ಎರಡರಲ್ಲಿ ೇನು ಲಾ ಅಮೆಂಡ್ಮೆಂಟ್ ಆಗಿದೆ'], [' ರೈತರು ಯುವಕರು ಏನು ಭೂಮಿ ಇಟ್ಕೊಂಡಿದ್ದಾರೆ ಕೃಷಿ ಬಗ್ಗೆ ಆಸಕ್ತಿ ಇದೆ ಇವತ್ತೇನು ಎರಡು ಸಾವಿರದ ಒಂದು ಎರಡರಲ್ಲಿ ೇನು ಲಾ ಅಮೆಂಡ್ಮೆಂಟ್ ಆಗಿದೆ'])\n",
            "----------------------------------------\n",
            "\n",
            "Passage 3 (Relevance Score: 0.673):\n",
            "Audio File: SandalWoodNewsStories_159.mp3\n",
            "Time Range: 3520.00s - 3530.00s\n",
            "English Translation: (['There are two doubts in the minds of these farmers about going to the open market. One is what benefit will the farmers get in the open market. The second is what will happen if anyone cuts and takes away the crop for sale'], ['There are two doubts in the minds of these farmers about going to the open market. One is what benefit will the farmers get in the open market. The second is what will happen if anyone cuts and takes away the crop for sale'])\n",
            "Original Kannada: ([' ಅದು ಈ ರೈತರು ಮುಕ್ತ ಮಾರುಕಟ್ಟೆಗೆ ಹೋಗೋ ವಿಷಯದಲ್ಲಿ ಎರಡು ಅನುಮಾನಗಳಿವ ಒಂದು ಮುಕ್ತ ಮಾರುಕಟ್ಟೆಯಲ್ಲಿ ರೈತರಿಗೆ ಏನು ಅನುಕೂಲ ಆಗ್ತದೆ ಎರಡನೇದೇನಂದರೆ ಯಾರು ಬೇಕಿದ್ರೂ ಕಡ್ಕೊಂಡು ಹೋಗಿ ಮಾರಾಟಕ್ಕೆ ಕತ್ತಿದರೆ ಬೆಳೆದೊಂದು ಕಥತೆೆಯ ಏನದೆ'], [' ಅದು ಈ ರೈತರು ಮುಕ್ತ ಮಾರುಕಟ್ಟೆಗೆ ಹೋಗೋ ವಿಷಯದಲ್ಲಿ ಎರಡು ಅನುಮಾನಗಳಿವ ಒಂದು ಮುಕ್ತ ಮಾರುಕಟ್ಟೆಯಲ್ಲಿ ರೈತರಿಗೆ ಏನು ಅನುಕೂಲ ಆಗ್ತದೆ ಎರಡನೇದೇನಂದರೆ ಯಾರು ಬೇಕಿದ್ರೂ ಕಡ್ಕೊಂಡು ಹೋಗಿ ಮಾರಾಟಕ್ಕೆ ಕತ್ತಿದರೆ ಬೆಳೆದೊಂದು ಕಥತೆೆಯ ಏನದೆ'])\n",
            "----------------------------------------\n",
            "\n",
            "Choose an option:\n",
            "1. Transcribe and translate new audio\n",
            "2. Search existing transcriptions\n",
            "3. Quit\n",
            "\n",
            "Enter your choice (1-3): 3\n",
            "Thank you for using the system. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import gc\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "from pathlib import Path\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import pandas as pd\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from pydub import AudioSegment\n",
        "import ast\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "\n",
        "class CombinedAudioSystem:\n",
        "    def __init__(self, model_path: str, csv_path: str, audio_dir: str, output_dir: str = \"./extracted_segments\"):\n",
        "        \"\"\"Initialize both ASR and RAG systems\"\"\"\n",
        "        # Initialize ASR model\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.asr_model = self.setup_model(model_path)\n",
        "\n",
        "        # Initialize Gemini\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC29gObkycJDBjVkEWjhJoJO-HVB0pC00E\"\n",
        "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "\n",
        "        # Initialize RAG system\n",
        "        self.csv_path = csv_path\n",
        "        self.audio_dir = audio_dir\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Load existing data and initialize RAG\n",
        "        self.df = self.load_and_prepare_data()\n",
        "        self.documents = self.create_documents()\n",
        "        self.vector_store = self.initialize_vector_store()\n",
        "        self.audio_cache = {}\n",
        "\n",
        "    def setup_model(self, model_path: str) -> nemo_asr.models.EncDecCTCModel:\n",
        "        \"\"\"Initialize the ASR model.\"\"\"\n",
        "        model = nemo_asr.models.EncDecCTCModel.restore_from(restore_path=model_path)\n",
        "        model.freeze()\n",
        "        model = model.to(self.device)\n",
        "        return model\n",
        "\n",
        "    def process_audio(self, audio_path: str) -> Tuple[torch.Tensor, int]:\n",
        "        \"\"\"Load and preprocess audio file.\"\"\"\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "        resampled_waveform = resampler(waveform)\n",
        "\n",
        "        if resampled_waveform.size(0) > 1:\n",
        "            resampled_waveform = resampled_waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        return resampled_waveform.squeeze(0), 16000\n",
        "\n",
        "    def translate_text(self, text: str) -> str:\n",
        "        \"\"\"Translate Kannada text to English and extract questions.\"\"\"\n",
        "        prompt = f\"Translate this Kannada text to English and identify any questions in the text. Format: TRANSLATION: <translation>\\nQUESTIONS: <list of questions>: {text}\"\n",
        "        try:\n",
        "            response = self.llm.invoke(prompt)\n",
        "            response_text = str(response.content)\n",
        "\n",
        "            # Parse the response to separate translation and questions\n",
        "            translation_match = re.search(r\"TRANSLATION:(.*?)(?=QUESTIONS:|$)\", response_text, re.DOTALL)\n",
        "            questions_match = re.search(r\"QUESTIONS:(.*?)$\", response_text, re.DOTALL)\n",
        "\n",
        "            translation = translation_match.group(1).strip() if translation_match else response_text\n",
        "            questions = questions_match.group(1).strip() if questions_match else \"\"\n",
        "\n",
        "            return translation, questions.split('\\n') if questions else []\n",
        "        except Exception as e:\n",
        "            return f\"Translation error: {str(e)}\", []\n",
        "\n",
        "    def transcribe_and_translate_audio(self, audio_path: str) -> tuple:\n",
        "        \"\"\"Transcribe audio, translate the transcription, and extract questions.\"\"\"\n",
        "        try:\n",
        "            input_signal, _ = self.process_audio(audio_path)\n",
        "            input_signal = input_signal.to(self.device)\n",
        "\n",
        "            transcript = self.asr_model.transcribe(\n",
        "                input_signal,\n",
        "                batch_size=1,\n",
        "                logprobs=False,\n",
        "                language_id='kn'\n",
        "            )[0]\n",
        "\n",
        "            translation, questions = self.translate_text(transcript)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            del input_signal\n",
        "            gc.collect()\n",
        "\n",
        "            return transcript, translation, questions\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing audio: {str(e)}\", \"Translation not available due to error\", []\n",
        "\n",
        "# [Previous imports and class definition remain the same until extract_audio_segment method]\n",
        "\n",
        "    def extract_audio_segment(self, audio_file: str, time_range: str) -> str:\n",
        "        \"\"\"Extract audio segment based on time range.\"\"\"\n",
        "        try:\n",
        "            # Clean and parse time range string\n",
        "            # Remove 's' suffix and whitespace, then split on hyphen\n",
        "            clean_range = time_range.replace('s', '').strip()\n",
        "            if '-' in clean_range:\n",
        "                start_str, end_str = clean_range.split('-')\n",
        "            else:\n",
        "                # Handle single timestamp format (assuming it's the end time with 0 as start)\n",
        "                start_str, end_str = '0', clean_range\n",
        "\n",
        "            # Convert to float, handling any remaining whitespace\n",
        "            start_time = float(start_str.strip())\n",
        "            end_time = float(end_str.strip())\n",
        "\n",
        "            # Create output filename\n",
        "            audio_name = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "            output_filename = f\"{audio_name}_{start_time:.2f}-{end_time:.2f}.wav\"\n",
        "            output_path = os.path.join(self.output_dir, output_filename)\n",
        "\n",
        "            # Check if segment already exists\n",
        "            if os.path.exists(output_path):\n",
        "                return output_path\n",
        "\n",
        "            # Load audio file\n",
        "            audio_path = os.path.join(self.audio_dir, audio_file)\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "            # Extract segment (convert to milliseconds)\n",
        "            start_ms = int(start_time * 1000)\n",
        "            end_ms = int(end_time * 1000)\n",
        "            segment = audio[start_ms:end_ms]\n",
        "\n",
        "            # Export segment\n",
        "            segment.export(output_path, format=\"wav\")\n",
        "            return output_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting audio segment: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def load_and_prepare_data(self) -> pd.DataFrame:\n",
        "        \"\"\"Load and prepare the CSV data.\"\"\"\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "        df['time_aligned_transcripts'] = df['time_aligned_transcripts'].apply(\n",
        "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        "        )\n",
        "        df['time_aligned_translations'] = df['time_aligned_translations'].apply(\n",
        "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        "        )\n",
        "        return df\n",
        "\n",
        "    def create_documents(self) -> List[Document]:\n",
        "        \"\"\"Create documents for vector store.\"\"\"\n",
        "        documents = []\n",
        "        for idx, row in self.df.iterrows():\n",
        "            for time_range, translation in row['time_aligned_translations'].items():\n",
        "                metadata = {\n",
        "                    'audio_file': row['audio_file'],\n",
        "                    'time_range': time_range,\n",
        "                    'original_text': row['time_aligned_transcripts'].get(time_range, ''),\n",
        "                    'full_translation': row['full_transcript_translation']\n",
        "                }\n",
        "                doc = Document(\n",
        "                    page_content=translation,\n",
        "                    metadata=metadata\n",
        "                )\n",
        "                documents.append(doc)\n",
        "        return documents\n",
        "\n",
        "    def initialize_vector_store(self) -> FAISS:\n",
        "        \"\"\"Initialize the FAISS vector store.\"\"\"\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "        )\n",
        "        return FAISS.from_documents(self.documents, embeddings)\n",
        "\n",
        "    def calculate_relevance_score(self, question: str, doc: Document) -> float:\n",
        "        \"\"\"Calculate relevance score for document.\"\"\"\n",
        "        try:\n",
        "            embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "            )\n",
        "            question_emb = embeddings.embed_query(question)\n",
        "            doc_emb = embeddings.embed_query(doc.page_content)\n",
        "\n",
        "            semantic_score = F.cosine_similarity(\n",
        "                torch.tensor(question_emb).unsqueeze(0),\n",
        "                torch.tensor(doc_emb).unsqueeze(0)\n",
        "            ).item()\n",
        "\n",
        "            return semantic_score\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating relevance score: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def answer_question(self, question: str, k: int = 3) -> List[Dict]:\n",
        "        \"\"\"Search for relevant passages and return results with extracted audio segments.\"\"\"\n",
        "        docs = self.vector_store.similarity_search(question, k=k)\n",
        "        results = []\n",
        "\n",
        "        for doc in docs:\n",
        "            score = self.calculate_relevance_score(question, doc)\n",
        "\n",
        "            # Extract audio segment\n",
        "            extracted_audio_path = self.extract_audio_segment(\n",
        "                doc.metadata['audio_file'],\n",
        "                doc.metadata['time_range']\n",
        "            )\n",
        "\n",
        "            result = {\n",
        "                'relevance_score': score,\n",
        "                'audio_file': doc.metadata['audio_file'],\n",
        "                'time_range': doc.metadata['time_range'],\n",
        "                'english_translation': doc.page_content,\n",
        "                'original_kannada': doc.metadata['original_text'],\n",
        "                'extracted_audio_path': extracted_audio_path\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "        return sorted(results, key=lambda x: x['relevance_score'], reverse=True)\n",
        "\n",
        "    def print_results(self, results: List[Dict]):\n",
        "        \"\"\"Print results in a formatted way.\"\"\"\n",
        "        if not results:\n",
        "            print(\"\\nNo relevant passages found.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\nRelevant passages found (ranked by relevance):\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            print(f\"\\nPassage {i} (Relevance Score: {result['relevance_score']:.3f}):\")\n",
        "            print(f\"Audio File: {result['audio_file']}\")\n",
        "            print(f\"Time Range: {result['time_range']}\")\n",
        "            print(f\"English Translation: {result['english_translation']}\")\n",
        "            print(f\"Original Kannada: {result['original_kannada']}\")\n",
        "            print(f\"Extracted Audio Segment: {result['extracted_audio_path']}\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    model_path = '/content/ai4b_indicConformer_kn.nemo'\n",
        "    csv_path = \"/content/allfilescombined.csv\"\n",
        "    audio_dir = \"/content/audio-kannada\"\n",
        "    output_dir = \"/content/extracted_segments3\"\n",
        "\n",
        "    print(\"Welcome to the Combined Audio Processing System!\")\n",
        "\n",
        "    try:\n",
        "        print(\"\\nInitializing system...\")\n",
        "        system = CombinedAudioSystem(model_path, csv_path, audio_dir, output_dir)\n",
        "        print(\"System initialized successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing system: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nChoose an option:\")\n",
        "        print(\"1. Process audio and answer questions from it\")\n",
        "        print(\"2. Search existing transcriptions\")\n",
        "        print(\"3. Quit\")\n",
        "\n",
        "        choice = input(\"\\nEnter your choice (1-3): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            print(\"\\nEnter the path to your audio file:\")\n",
        "            audio_path = input().strip()\n",
        "\n",
        "            if not os.path.exists(audio_path):\n",
        "                print(\"Error: File does not exist.\")\n",
        "                continue\n",
        "\n",
        "            if not audio_path.lower().endswith(('.mp3', '.wav', '.flac', '.ogg')):\n",
        "                print(\"Error: File must be an audio file (mp3, wav, flac, or ogg)\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nProcessing {os.path.basename(audio_path)}...\")\n",
        "            transcript, translation, questions = system.transcribe_and_translate_audio(audio_path)\n",
        "\n",
        "            print(\"\\nResults:\")\n",
        "            print(\"-\" * 50)\n",
        "            print(\"Original Kannada Transcription:\")\n",
        "            print(transcript)\n",
        "            print(\"\\nEnglish Translation:\")\n",
        "            print(translation)\n",
        "\n",
        "            if questions:\n",
        "                print(\"\\nQuestions detected in the audio:\")\n",
        "                for i, question in enumerate(questions, 1):\n",
        "                    print(f\"\\nQuestion {i}: {question}\")\n",
        "                    results = system.answer_question(question)\n",
        "                    system.print_results(results)\n",
        "            else:\n",
        "                print(\"\\nNo questions detected in the audio content.\")\n",
        "\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            question = input(\"\\nEnter your search query: \")\n",
        "            results = system.answer_question(question)\n",
        "            system.print_results(results)\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            print(\"Thank you for using the system. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "dmwPKGqSDg-T",
        "outputId": "a0c570c5-75fb-436f-b507-95b230fffafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Combined Audio Processing System!\n",
            "\n",
            "Initializing system...\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:198] _setup_tokenizer: detected an aggregate tokenizer\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2024-11-17 17:11:16 multilingual_tokenizer:61] Aggregate vocab size: 5632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-17 17:11:26 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/train/train_kannada.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    max_duration: 30.0\n",
            "    min_duration: 0.2\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    shuffle_n: 2048\n",
            "    bucketing_strategy: synced_randomized\n",
            "    bucketing_batch_size: null\n",
            "    is_concat: true\n",
            "    concat_sampling_technique: temperature\n",
            "    concat_sampling_temperature: 1.5\n",
            "    return_language_id: true\n",
            "    \n",
            "[NeMo W 2024-11-17 17:11:26 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/valid_datasetwise/valid_kannada_indicvoices.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    return_language_id: true\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-17 17:11:26 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-17 17:11:26 features:289] PADDING: 0\n",
            "[NeMo I 2024-11-17 17:11:29 rnnt:1663] Vocab size for each language: 256\n",
            "[NeMo I 2024-11-17 17:11:30 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 17:11:30 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 17:11:32 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 17:11:32 hybrid_rnnt_ctc_bpe_models:105] Creating masks for multi-softmax layer.\n",
            "[NeMo I 2024-11-17 17:11:32 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2024-11-17 17:11:33 save_restore_connector:263] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /content/ai4b_indicConformer_kn.nemo.\n",
            "System initialized successfully!\n",
            "\n",
            "Choose an option:\n",
            "1. Process audio and answer questions from it\n",
            "2. Search existing transcriptions\n",
            "3. Quit\n",
            "\n",
            "Enter your choice (1-3): 1\n",
            "\n",
            "Enter the path to your audio file:\n",
            "/content/Test.mp3\n",
            "\n",
            "Processing Test.mp3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 18.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "--------------------------------------------------\n",
            "Original Kannada Transcription:\n",
            "[' ರೈತರ ಬಗ್ಗೆ ಏನು ಪ್ರಸ್ತಾಪಿಸಲಾಗಿದೆ']\n",
            "\n",
            "English Translation:\n",
            "The farmers in the state have been constantly demanding for a separate budget.\n",
            "\n",
            "Questions detected in the audio:\n",
            "\n",
            "Question 1: ['What is proposed about the farmers']\n",
            "\n",
            "Relevant passages found (ranked by relevance):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Passage 1 (Relevance Score: 0.732):\n",
            "Audio File: SandalWoodNewsStories_286.mp3\n",
            "Time Range: 200.00s - 210.00s\n",
            "English Translation: ([ ' Can be stopped and can be facilitated for the next younger generation, as my personal opinion I am requesting all the farmers'], [' Can be stopped and can be facilitated for the next younger generation, as my personal opinion I am requesting all the farmers'])\n",
            "Original Kannada: ([' ತಡೆ ಹಿಡಿಬಹದು ತಡೆ ಹಿಡಿದು ಮುಂದಿನ ಯುವ ಪೀಳಿಗೆಗೆ ಅನುಕೂಲ ಮಾಡಿ ಕೊಡಬಹುದು ಅಂತ ನನ್ನ ಒಂದು ವೈಯಕ್ತಿಕ ವಿಚಾರವಾಗಿ ಎಲ್ಲ ರೈತರಲ್ಲಿ ನಾನು ಕಳ್ಕಳಿ ಮನವಿ ಮಾಡ್ಕೊಂತಿದೀನಿ'], [' ತಡೆ ಹಿಡಿಬಹದು ತಡೆ ಹಿಡಿದು ಮುಂದಿನ ಯುವ ಪೀಳಿಗೆಗೆ ಅನುಕೂಲ ಮಾಡಿ ಕೊಡಬಹುದು ಅಂತ ನನ್ನ ಒಂದು ವೈಯಕ್ತಿಕ ವಿಚಾರವಾಗಿ ಎಲ್ಲ ರೈತರಲ್ಲಿ ನಾನು ಕಳ್ಕಳಿ ಮನವಿ ಮಾಡ್ಕೊಂತಿದೀನಿ'])\n",
            "Extracted Audio Segment: /content/extracted_segments3/SandalWoodNewsStories_286_200.00-210.00.wav\n",
            "----------------------------------------\n",
            "\n",
            "Passage 2 (Relevance Score: 0.721):\n",
            "Audio File: SandalWoodNewsStories_175.mp3\n",
            "Time Range: 180.00s - 190.00s\n",
            "English Translation: ['Farmers and young people who have lands and are interested in agriculture, the land amendment act of 2001 and 2002'], ['Farmers and young people who have lands and are interested in agriculture, the land amendment act of 2001 and 2002'])\n",
            "Original Kannada: ([' ರೈತರು ಯುವಕರು ಏನು ಭೂಮಿ ಇಟ್ಕೊಂಡಿದ್ದಾರೆ ಕೃಷಿ ಬಗ್ಗೆ ಆಸಕ್ತಿ ಇದೆ ಇವತ್ತೇನು ಎರಡು ಸಾವಿರದ ಒಂದು ಎರಡರಲ್ಲಿ ೇನು ಲಾ ಅಮೆಂಡ್ಮೆಂಟ್ ಆಗಿದೆ'], [' ರೈತರು ಯುವಕರು ಏನು ಭೂಮಿ ಇಟ್ಕೊಂಡಿದ್ದಾರೆ ಕೃಷಿ ಬಗ್ಗೆ ಆಸಕ್ತಿ ಇದೆ ಇವತ್ತೇನು ಎರಡು ಸಾವಿರದ ಒಂದು ಎರಡರಲ್ಲಿ ೇನು ಲಾ ಅಮೆಂಡ್ಮೆಂಟ್ ಆಗಿದೆ'])\n",
            "Extracted Audio Segment: /content/extracted_segments3/SandalWoodNewsStories_175_180.00-190.00.wav\n",
            "----------------------------------------\n",
            "\n",
            "Passage 3 (Relevance Score: 0.720):\n",
            "Audio File: SandalWoodNewsStories_303.mp3\n",
            "Time Range: 60.00s - 70.00s\n",
            "English Translation: (['farmers should be careful in this one issue if it is said that there is no need for government's'], ['farmers should be careful in this one issue if it is said that there is no need for government's'])\n",
            "Original Kannada: ([' ಸಕಾರದ ಯಾವುನ್ ಅಥವಾ ಅನುಮತಿಯ ಅಗತ್ಯತೆ ಇಲ್ಲ ಎಂಬುದನ್ನು ಹೇಳಿದರೆ ಈ ಒಂದು ವಿಷಯದಲ್ಲಿ ರೈತರು ಜಾಗೃತರಾಗಬೇಕು ಮತ್ತು'], [' ಸಕಾರದ ಯಾವುನ್ ಅಥವಾ ಅನುಮತಿಯ ಅಗತ್ಯತೆ ಇಲ್ಲ ಎಂಬುದನ್ನು ಹೇಳಿದರೆ ಈ ಒಂದು ವಿಷಯದಲ್ಲಿ ರೈತರು ಜಾಗೃತರಾಗಬೇಕು ಮತ್ತು'])\n",
            "Extracted Audio Segment: /content/extracted_segments3/SandalWoodNewsStories_303_60.00-70.00.wav\n",
            "----------------------------------------\n",
            "--------------------------------------------------\n",
            "\n",
            "Choose an option:\n",
            "1. Process audio and answer questions from it\n",
            "2. Search existing transcriptions\n",
            "3. Quit\n",
            "\n",
            "Enter your choice (1-3): 3\n",
            "Thank you for using the system. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}